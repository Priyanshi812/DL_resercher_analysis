{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "def extract_abstract_column(df):\n",
        "    for col in df.columns:\n",
        "        if col.strip().lower() == 'abstract':\n",
        "            return col\n",
        "    return None\n",
        "def extract_tfidf_from_excel(file_path, max_keywords=10):\n",
        "    xls = pd.ExcelFile(file_path)\n",
        "    for sheet_name in xls.sheet_names:\n",
        "        try:\n",
        "            df = pd.read_excel(xls, sheet_name=sheet_name, header=1)\n",
        "            abstract_col = extract_abstract_column(df)\n",
        "            if not abstract_col:\n",
        "                print(f\" No 'Abstract' column in: {sheet_name}\")\n",
        "                continue\n",
        "            abstracts = df[abstract_col].dropna().astype(str).tolist()\n",
        "            if not abstracts:\n",
        "                print(f\"No abstracts in sheet: {sheet_name}\")\n",
        "                continue\n",
        "            combined_text = ' '.join(abstracts)\n",
        "            vectorizer = TfidfVectorizer(stop_words='english', max_features=max_keywords)\n",
        "            X = vectorizer.fit_transform([combined_text])\n",
        "            keywords = vectorizer.get_feature_names_out()\n",
        "            print(f\"\\n Researcher: {sheet_name}\")\n",
        "            print(\"Top Keywords:\", ', '.join(keywords))\n",
        "        except Exception as e:\n",
        "            print(f\" Error in sheet {sheet_name}: {e}\")\n",
        "extract_tfidf_from_excel(\"/content/DL-TASK1.xlsx\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuoDtgsVwXIp",
        "outputId": "48834dae-0376-4195-a26f-36f89ffce58e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " No 'Abstract' column in: 1-Danqi Chen\n",
            "\n",
            " Researcher: 2-Kai Zhao\n",
            "Top Keywords: based, chitosan, control, error, estimation, method, performance, proposed, state, water\n",
            "\n",
            " Researcher: 3-Irene Li\n",
            "Top Keywords: based, framework, knowledge, language, large, llms, medical, models, patients, qa\n",
            "\n",
            " Researcher: 4-Linqi Song\n",
            "Top Keywords: based, code, data, federated, learning, llms, methods, model, models, user\n",
            "\n",
            " Researcher: 5-Thang Vu\n",
            "Top Keywords: anchors, bler, cascade, feqe, fronthaul, image, paper, proposed, rate, rpn\n",
            "\n",
            " Researcher: 6-Nora Hollenstein\n",
            "Top Keywords: data, eeg, eye, features, human, language, models, processing, reading, tracking\n",
            "\n",
            " Researcher: 7-Gabriella Lapesa\n",
            "Top Keywords: argument, datasets, definitions, discourse, llms, moderation, political, quality, research, sexism\n",
            "\n",
            " Researcher: 8-Qiaoqiao She\n",
            "Top Keywords: based, data, image, language, model, models, questions, table, text, training\n",
            "\n",
            " Researcher: 9-Ashkan Kazemi\n",
            "Top Keywords: claim, claims, fact, language, matching, misinformation, models, mscs, scale, textrank\n",
            "\n",
            " Researcher: 10-Yan Zhang\n",
            "Top Keywords: 95, absorption, action, cancer, cell, ci, detection, human, micro, results\n",
            "\n",
            " Researcher: 11-Arjun Reddy Akula\n",
            "Top Keywords: based, dataset, discourse, knowledge, language, models, task, video, visual, vqa\n",
            "\n",
            " Researcher: 12-Saneem Ahmed Chemmengath\n",
            "Top Keywords: based, feature, features, learning, methods, performance, problems, select, selection, set\n",
            "\n",
            " Researcher: 14-William Merrill\n",
            "Top Keywords: depth, language, languages, models, problems, standard, state, tokens, transformer, transformers\n",
            "\n",
            " Researcher: 15-Yixin Nie\n",
            "Top Keywords: based, dataset, detection, ecl, high, human, model, models, qds, retrieval\n",
            "\n",
            " Researcher: 13-Urmish Thakker\n",
            "Top Keywords: accuracy, data, language, large, learning, llms, memory, model, models, training\n",
            "\n",
            " Researcher: 16-Zhiqing Sun\n",
            "Top Keywords: ai, based, human, language, learning, model, models, performance, propose, tasks\n",
            " No 'Abstract' column in: Author_Profile\n",
            "\n",
            " Researcher: 17-Jinhua Du\n",
            "Top Keywords: based, ceramics, eawm, ec, emission, energy, high, o3, results, sources\n",
            "\n",
            " Researcher: 18-Prashant Mathur\n",
            "Top Keywords: 95, based, breast, cancer, ci, india, speech, survival, translation, urban\n",
            "\n",
            " Researcher: 19-Sanqiang Zhao\n",
            "Top Keywords: data, different, instruction, method, model, models, sentence, simplification, text, training\n",
            "\n",
            " Researcher: 20-Md Mosharaf Hossain\n",
            "Top Keywords: 19, 95, analysis, bangladesh, ci, factors, negation, plexina1, risk, study\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import pandas as pd\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "excel_path = '/content/DL-TASK1.xlsx'\n",
        "all_abstracts = []\n",
        "xls = pd.ExcelFile(excel_path)\n",
        "for sheet_name in xls.sheet_names:\n",
        "    df = xls.parse(sheet_name)\n",
        "    df.columns = [col.lower() for col in df.columns]\n",
        "    if 'abstract' in df.columns:\n",
        "        abstracts = df['abstract'].dropna().astype(str).tolist()\n",
        "        all_abstracts.extend(abstracts)\n",
        "all_abstracts = all_abstracts[:20]\n",
        "if len(all_abstracts) < 2:\n",
        "    print(\"Not enough abstracts found to compare. Found:\", len(all_abstracts))\n",
        "else:\n",
        "    embeddings = model.encode(all_abstracts, convert_to_tensor=True)\n",
        "    cosine_scores = util.pytorch_cos_sim(embeddings, embeddings)\n",
        "    pairwise_scores = [\n",
        "        cosine_scores[i][j].item()\n",
        "        for i in range(len(all_abstracts))\n",
        "        for j in range(i + 1, len(all_abstracts))\n",
        "    ]\n",
        "    if pairwise_scores:\n",
        "        average_similarity = sum(pairwise_scores) / len(pairwise_scores)\n",
        "        print(\"Average Pairwise Similarity Score:\", round(average_similarity, 4))\n",
        "        if average_similarity > 0.75:\n",
        "            print(\"Most abstracts are on a focused area.\")\n",
        "        elif average_similarity < 0.5:\n",
        "            print(\"Abstracts cover diverse topics.\")\n",
        "        else:\n",
        "            print(\"Moderate similarity: Some overlap, some diversity.\")\n",
        "    else:\n",
        "        print(\"No pairwise comparisons were made.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrKneGHF3kjS",
        "outputId": "78017a0f-022d-453a-9fb2-532f82eabf31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not enough abstracts found to compare. Found: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import pandas as pd\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "excel_path = '/content/DL-TASK1.xlsx'\n",
        "xls = pd.ExcelFile(excel_path)\n",
        "results = []\n",
        "print(\"\\n--- Computing Similarity Per Researcher ---\")\n",
        "for sheet_name in xls.sheet_names:\n",
        "    try:\n",
        "        df = xls.parse(sheet_name, header=1)\n",
        "        df.columns = [col.strip().lower() for col in df.columns]\n",
        "\n",
        "        if 'abstract' in df.columns:\n",
        "            abstracts = df['abstract'].dropna().astype(str).tolist()\n",
        "\n",
        "            if len(abstracts) < 2:\n",
        "                print(f\" Not enough abstracts for: {sheet_name} (found {len(abstracts)})\")\n",
        "                results.append((sheet_name, len(abstracts), \"N/A\", \"Not Enough Data\"))\n",
        "                continue\n",
        "            embeddings = model.encode(abstracts, convert_to_tensor=True)\n",
        "            cosine_scores = util.pytorch_cos_sim(embeddings, embeddings)\n",
        "            pairwise_scores = [\n",
        "                cosine_scores[i][j].item()\n",
        "                for i in range(len(abstracts))\n",
        "                for j in range(i + 1, len(abstracts))\n",
        "            ]\n",
        "            avg_similarity = sum(pairwise_scores) / len(pairwise_scores)\n",
        "            if avg_similarity >= 0.6:\n",
        "                diversity = \" Highly Focused\"\n",
        "            elif avg_similarity >= 0.3:\n",
        "                diversity = \"Moderately Diverse\"\n",
        "            else:\n",
        "                diversity = \"Highly Diverse\"\n",
        "            results.append((sheet_name, len(abstracts), round(avg_similarity, 4), diversity))\n",
        "        else:\n",
        "            print(f\" 'Abstract' column not found in sheet: {sheet_name}\")\n",
        "            results.append((sheet_name, 0, \"N/A\", \"No Abstract Column\"))\n",
        "    except Exception as e:\n",
        "        print(f\" Error processing {sheet_name}: {e}\")\n",
        "        results.append((sheet_name, 0, \"Error\", \"Processing Error\"))\n",
        "print(\"\\nPer Researcher Similarity & Diversity Classification:\")\n",
        "print(f\"{'Researcher':<30} | {'#Abstracts':<10} | {'Avg Similarity':<15} | {'Diversity'}\")\n",
        "print(\"-\" * 80)\n",
        "for name, count, score, diversity in results:\n",
        "    print(f\"{name:<30} | {count:<10} | {score:<15} | {diversity}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yG8f-wvO5wax",
        "outputId": "bb9fca8d-b4fa-4a84-b129-bc3cd7b86dc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Computing Similarity Per Researcher ---\n",
            " 'Abstract' column not found in sheet: 1-Danqi Chen\n",
            " 'Abstract' column not found in sheet: Author_Profile\n",
            "\n",
            "Per Researcher Similarity & Diversity Classification:\n",
            "Researcher                     | #Abstracts | Avg Similarity  | Diversity\n",
            "--------------------------------------------------------------------------------\n",
            "1-Danqi Chen                   | 0          | N/A             | No Abstract Column\n",
            "2-Kai Zhao                     | 20         | 0.047           | Highly Diverse\n",
            "3-Irene Li                     | 20         | 0.2638          | Highly Diverse\n",
            "4-Linqi Song                   | 20         | 0.2621          | Highly Diverse\n",
            "5-Thang Vu                     | 4          | 0.2877          | Highly Diverse\n",
            "6-Nora Hollenstein             | 20         | 0.5227          | Moderately Diverse\n",
            "7-Gabriella Lapesa             | 20         | 0.4671          | Moderately Diverse\n",
            "8-Qiaoqiao She                 | 13         | 0.4311          | Moderately Diverse\n",
            "9-Ashkan Kazemi                | 14         | 0.2868          | Highly Diverse\n",
            "10-Yan Zhang                   | 20         | 0.0776          | Highly Diverse\n",
            "11-Arjun Reddy Akula           | 20         | 0.3002          | Moderately Diverse\n",
            "12-Saneem Ahmed Chemmengath    | 8          | 0.3715          | Moderately Diverse\n",
            "14-William Merrill             | 20         | 0.3296          | Moderately Diverse\n",
            "15-Yixin Nie                   | 20         | 0.2291          | Highly Diverse\n",
            "13-Urmish Thakker              | 20         | 0.4001          | Moderately Diverse\n",
            "16-Zhiqing Sun                 | 20         | 0.2902          | Highly Diverse\n",
            "Author_Profile                 | 0          | N/A             | No Abstract Column\n",
            "17-Jinhua Du                   | 20         | 0.1444          | Highly Diverse\n",
            "18-Prashant Mathur             | 6          | 0.218           | Highly Diverse\n",
            "19-Sanqiang Zhao               | 20         | 0.2688          | Highly Diverse\n",
            "20-Md Mosharaf Hossain         | 20         | 0.1196          | Highly Diverse\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import itertools\n",
        "import random\n",
        "data = [\n",
        "    {\"Researcher\": \"Kai Zhao\", \"Similarity\": 0.047},\n",
        "    {\"Researcher\": \"Irene Li\", \"Similarity\": 0.2638},\n",
        "    {\"Researcher\": \"Linqi Song\", \"Similarity\": 0.2621},\n",
        "    {\"Researcher\": \"Thang Vu\", \"Similarity\": 0.2877},\n",
        "    {\"Researcher\": \"Nora Hollenstein\", \"Similarity\": 0.5227},\n",
        "    {\"Researcher\": \"Gabriella Lapesa\", \"Similarity\": 0.4671},\n",
        "    {\"Researcher\": \"Qiaoqiao She\", \"Similarity\": 0.4311},\n",
        "    {\"Researcher\": \"Ashkan Kazemi\", \"Similarity\": 0.2868},\n",
        "    {\"Researcher\": \"Yan Zhang\", \"Similarity\": 0.0776},\n",
        "    {\"Researcher\": \"Arjun Reddy Akula\", \"Similarity\": 0.3002},\n",
        "    {\"Researcher\": \"Saneem Ahmed Chemmengath\", \"Similarity\": 0.3715},\n",
        "    {\"Researcher\": \"William Merrill\", \"Similarity\": 0.3296},\n",
        "    {\"Researcher\": \"Yixin Nie\", \"Similarity\": 0.2291},\n",
        "    {\"Researcher\": \"Urmish Thakker\", \"Similarity\": 0.4001},\n",
        "    {\"Researcher\": \"Zhiqing Sun\", \"Similarity\": 0.2902},\n",
        "    {\"Researcher\": \"Jinhua Du\", \"Similarity\": 0.1444},\n",
        "    {\"Researcher\": \"Prashant Mathur\", \"Similarity\": 0.218},\n",
        "    {\"Researcher\": \"Sanqiang Zhao\", \"Similarity\": 0.2688},\n",
        "    {\"Researcher\": \"Md Mosharaf Hossain\", \"Similarity\": 0.1196}\n",
        "]\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "def classify_diversity(sim):\n",
        "    if sim < 0.2:\n",
        "        return \"Highly Diverse\"\n",
        "    elif sim < 0.5:\n",
        "        return \"Moderately Diverse\"\n",
        "    else:\n",
        "        return \"Less Diverse\"\n",
        "\n",
        "df[\"DiversityLevel\"] = df[\"Similarity\"].apply(classify_diversity)\n",
        "high_diverse = df[df[\"DiversityLevel\"] == \"Highly Diverse\"]\n",
        "mod_diverse = df[df[\"DiversityLevel\"] == \"Moderately Diverse\"]\n",
        "pairs = list(itertools.product(high_diverse[\"Researcher\"], mod_diverse[\"Researcher\"]))\n",
        "themes = [\n",
        "    {\n",
        "        \"theme\": \"Cognitive Multilingual Understanding\",\n",
        "        \"justification\": \"Pairing researchers exploring multilingual or cross-lingual models with those studying semantic or discourse-level representations enables deeper cognitive grounding.\",\n",
        "        \"fields\": \"Multilingual NLP + Cognitive Semantics\"\n",
        "    },\n",
        "    {\n",
        "        \"theme\": \"Explainable and Trustworthy NLP Systems\",\n",
        "        \"justification\": \"Merging low-overlap researchers with moderate similarity can foster models that combine symbolic reasoning with deep learning for interpretability.\",\n",
        "        \"fields\": \"Explainable AI + Neural Reasoning\"\n",
        "    },\n",
        "    {\n",
        "        \"theme\": \"Cross-Domain Adaptation for Low-Resource Languages\",\n",
        "        \"justification\": \"Diverse linguistic expertise can complement domain-specialized NLP to build adaptable, transferable systems.\",\n",
        "        \"fields\": \"Transfer Learning + Domain-Specific NLP\"\n",
        "    }\n",
        "]\n",
        "random.seed(42)\n",
        "selected_pairs = random.sample(pairs, 3)\n",
        "results = []\n",
        "for idx, (r1, r2) in enumerate(selected_pairs):\n",
        "    theme = themes[idx % len(themes)]\n",
        "    results.append({\n",
        "        \"Researcher 1\": r1,\n",
        "        \"Researcher 2\": r2,\n",
        "        \"Collaboration Theme\": theme[\"theme\"],\n",
        "        \"Justification\": theme[\"justification\"],\n",
        "        \"Fields Bridged\": theme[\"fields\"]\n",
        "    })\n",
        "collab_df = pd.DataFrame(results)\n",
        "print(collab_df)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnKEbYjUBmex",
        "outputId": "6ff77d01-2efa-4ede-9245-fba6828313a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Researcher 1              Researcher 2  \\\n",
            "0    Jinhua Du           Prashant Mathur   \n",
            "1     Kai Zhao  Saneem Ahmed Chemmengath   \n",
            "2     Kai Zhao                Linqi Song   \n",
            "\n",
            "                                 Collaboration Theme  \\\n",
            "0               Cognitive Multilingual Understanding   \n",
            "1            Explainable and Trustworthy NLP Systems   \n",
            "2  Cross-Domain Adaptation for Low-Resource Langu...   \n",
            "\n",
            "                                       Justification  \\\n",
            "0  Pairing researchers exploring multilingual or ...   \n",
            "1  Merging low-overlap researchers with moderate ...   \n",
            "2  Diverse linguistic expertise can complement do...   \n",
            "\n",
            "                            Fields Bridged  \n",
            "0   Multilingual NLP + Cognitive Semantics  \n",
            "1        Explainable AI + Neural Reasoning  \n",
            "2  Transfer Learning + Domain-Specific NLP  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "def extract_abstract_column(df):\n",
        "    for col in df.columns:\n",
        "        if isinstance(col, str) and col.strip().lower() == 'abstract':\n",
        "            return col\n",
        "    return None\n",
        "\n",
        "def extract_tfidf_from_excel(file_path, max_keywords=10):\n",
        "    xls = pd.ExcelFile(file_path)\n",
        "\n",
        "    for sheet_name in xls.sheet_names:\n",
        "        try:\n",
        "            found = False\n",
        "            for header_row in range(0, 5):  # Try first 5 rows as header candidates\n",
        "                df = pd.read_excel(xls, sheet_name=sheet_name, header=header_row)\n",
        "                abstract_col = extract_abstract_column(df)\n",
        "\n",
        "                if abstract_col:\n",
        "                    found = True\n",
        "                    break\n",
        "\n",
        "            if not found:\n",
        "                print(f\" No 'Abstract' column in: {sheet_name}\")\n",
        "                continue\n",
        "\n",
        "            abstracts = df[abstract_col].dropna().astype(str).tolist()\n",
        "            if not abstracts:\n",
        "                print(f\"No abstracts in sheet: {sheet_name}\")\n",
        "                continue\n",
        "\n",
        "            combined_text = ' '.join(abstracts)\n",
        "\n",
        "            vectorizer = TfidfVectorizer(stop_words='english', max_features=max_keywords)\n",
        "            X = vectorizer.fit_transform([combined_text])\n",
        "            keywords = vectorizer.get_feature_names_out()\n",
        "\n",
        "            print(f\"\\n Researcher: {sheet_name}\")\n",
        "            print(\"Top Keywords:\", ', '.join(keywords))\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in sheet {sheet_name}: {e}\")\n",
        "\n",
        "# Example usage\n",
        "extract_tfidf_from_excel(\"/content/DL-TASK1.xlsx\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulPnyDINRxxp",
        "outputId": "788568ab-f24e-4b4d-eb75-dde792f89ded"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Researcher: 1-Danqi Chen\n",
            "Top Keywords: data, knowledge, language, llms, model, models, performance, task, tasks, training\n",
            "\n",
            " Researcher: 2-Kai Zhao\n",
            "Top Keywords: based, chitosan, control, error, estimation, method, performance, proposed, state, water\n",
            "\n",
            " Researcher: 3-Irene Li\n",
            "Top Keywords: based, framework, knowledge, language, large, llms, medical, models, patients, qa\n",
            "\n",
            " Researcher: 4-Linqi Song\n",
            "Top Keywords: based, code, data, federated, learning, llms, methods, model, models, user\n",
            "\n",
            " Researcher: 5-Thang Vu\n",
            "Top Keywords: anchors, bler, cascade, feqe, fronthaul, image, paper, proposed, rate, rpn\n",
            "\n",
            " Researcher: 6-Nora Hollenstein\n",
            "Top Keywords: data, eeg, eye, features, human, language, models, processing, reading, tracking\n",
            "\n",
            " Researcher: 7-Gabriella Lapesa\n",
            "Top Keywords: argument, datasets, definitions, discourse, llms, moderation, political, quality, research, sexism\n",
            "\n",
            " Researcher: 8-Qiaoqiao She\n",
            "Top Keywords: based, data, image, language, model, models, questions, table, text, training\n",
            "\n",
            " Researcher: 9-Ashkan Kazemi\n",
            "Top Keywords: claim, claims, fact, language, matching, misinformation, models, mscs, scale, textrank\n",
            "\n",
            " Researcher: 10-Yan Zhang\n",
            "Top Keywords: 95, absorption, action, cancer, cell, ci, detection, human, micro, results\n",
            "\n",
            " Researcher: 11-Arjun Reddy Akula\n",
            "Top Keywords: based, dataset, discourse, knowledge, language, models, task, video, visual, vqa\n",
            "\n",
            " Researcher: 12-Saneem Ahmed Chemmengath\n",
            "Top Keywords: based, feature, features, learning, methods, performance, problems, select, selection, set\n",
            "\n",
            " Researcher: 14-William Merrill\n",
            "Top Keywords: depth, language, languages, models, problems, standard, state, tokens, transformer, transformers\n",
            "\n",
            " Researcher: 15-Yixin Nie\n",
            "Top Keywords: based, dataset, detection, ecl, high, human, model, models, qds, retrieval\n",
            "\n",
            " Researcher: 13-Urmish Thakker\n",
            "Top Keywords: accuracy, data, language, large, learning, llms, memory, model, models, training\n",
            "\n",
            " Researcher: 16-Zhiqing Sun\n",
            "Top Keywords: ai, based, human, language, learning, model, models, performance, propose, tasks\n",
            " No 'Abstract' column in: Author_Profile\n",
            "\n",
            " Researcher: 17-Jinhua Du\n",
            "Top Keywords: based, ceramics, eawm, ec, emission, energy, high, o3, results, sources\n",
            "\n",
            " Researcher: 18-Prashant Mathur\n",
            "Top Keywords: 95, based, breast, cancer, ci, india, speech, survival, translation, urban\n",
            "\n",
            " Researcher: 19-Sanqiang Zhao\n",
            "Top Keywords: data, different, instruction, method, model, models, sentence, simplification, text, training\n",
            "\n",
            " Researcher: 20-Md Mosharaf Hossain\n",
            "Top Keywords: 19, 95, analysis, bangladesh, ci, factors, negation, plexina1, risk, study\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "\n",
        "# Load spaCy English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")  # Run `python -m spacy download en_core_web_sm` if not installed\n",
        "\n",
        "def extract_abstract_column(df):\n",
        "    for col in df.columns:\n",
        "        if col.strip().lower() == 'abstract':\n",
        "            return col\n",
        "    return None\n",
        "\n",
        "def perform_ner_from_excel(file_path):\n",
        "    xls = pd.ExcelFile(file_path)\n",
        "\n",
        "    for sheet_name in xls.sheet_names:\n",
        "        try:\n",
        "            df = pd.read_excel(xls, sheet_name=sheet_name, header=1)\n",
        "            abstract_col = extract_abstract_column(df)\n",
        "\n",
        "            if not abstract_col:\n",
        "                print(f\" No 'Abstract' column in: {sheet_name}\")\n",
        "                continue\n",
        "\n",
        "            abstracts = df[abstract_col].dropna().astype(str).tolist()\n",
        "            if not abstracts:\n",
        "                print(f\"No abstracts in sheet: {sheet_name}\")\n",
        "                continue\n",
        "\n",
        "            combined_text = ' '.join(abstracts)\n",
        "            doc = nlp(combined_text)\n",
        "\n",
        "            print(f\"\\n Researcher: {sheet_name}\")\n",
        "            print(\"Named Entities Found (label: text):\")\n",
        "            for ent in doc.ents:\n",
        "                print(f\"{ent.label_}: {ent.text}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\" Error in sheet {sheet_name}: {e}\")\n",
        "\n",
        "# Example usage\n",
        "perform_ner_from_excel(\"/content/DL-TASK1.xlsx\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JEt3HQTxJyR",
        "outputId": "a808cae5-9e69-4943-fbcd-09f273ee8014"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " No 'Abstract' column in: 1-Danqi Chen\n",
            "\n",
            " Researcher: 2-Kai Zhao\n",
            "Named Entities Found (label: text):\n",
            "DATE: 18 years ago\n",
            "ORG: CoVs\n",
            "ORG: CoVs\n",
            "MONEY: 2019-nCoV\n",
            "GPE: Wuhan\n",
            "GPE: China\n",
            "DATE: 12 December 2019\n",
            "CARDINAL: 2,794\n",
            "CARDINAL: 80\n",
            "DATE: 26 January 2020\n",
            "CARDINAL: five\n",
            "PERCENT: 79.6%\n",
            "DATE: 2019\n",
            "PERCENT: 96%\n",
            "CARDINAL: seven\n",
            "DATE: 2019\n",
            "CARDINAL: 2019\n",
            "ORG: IoT\n",
            "ORG: IoT\n",
            "ORG: IoT\n",
            "CARDINAL: three\n",
            "PERSON: Lyapunov\n",
            "ORG: BLF\n",
            "ORDINAL: First\n",
            "ORDINAL: second\n",
            "CARDINAL: around 10\n",
            "PERCENT: around 92%\n",
            "PERCENT: 13.1%\n",
            "PERCENT: 16.5%\n",
            "ORG: State\n",
            "PRODUCT: SoC\n",
            "NORP: Coulomb\n",
            "ORG: Kalman\n",
            "GPE: Kalman\n",
            "ORG: SoC\n",
            "NORP: Kalman\n",
            "ORDINAL: First\n",
            "ORDINAL: Second\n",
            "ORG: SoC\n",
            "ORG: OCV-SoC\n",
            "ORDINAL: Third\n",
            "ORG: AEKF\n",
            "ORG: SoC\n",
            "ORG: SoC\n",
            "PERCENT: less than 2%\n",
            "CARDINAL: one\n",
            "ORG: CNN\n",
            "ORG: ResNet\n",
            "ORG: DLA\n",
            "ORG: ImageNet\n",
            "ORG: https://mmcheng.net/res2net/.\n",
            "CARDINAL: 1\n",
            "CARDINAL: 2\n",
            "CARDINAL: 3\n",
            "CARDINAL: zero\n",
            "ORG: Euler-Lagrange\n",
            "PERSON: Lyapunov\n",
            "CARDINAL: 1\n",
            "NORP: C1\n",
            "CARDINAL: 2\n",
            "CARDINAL: 3\n",
            "ORG: Nussbaum\n",
            "CARDINAL: zero\n",
            "CARDINAL: 4\n",
            "ORG: NN\n",
            "PERSON: Lyapunov\n",
            "PERSON: Twitter\n",
            "CARDINAL: two\n",
            "PERSON: status1\n",
            "QUANTITY: 5-hydroxymethylcytosine\n",
            "CARDINAL: 5hmC\n",
            "CARDINAL: ten eleven\n",
            "PERSON: members2\n",
            "GPE: Tet\n",
            "ORG: uncovered3\n",
            "NORP: Tet\n",
            "ORG: Tet2\n",
            "ORG: IL-6\n",
            "ORG: Tet2\n",
            "ORG: IL-6\n",
            "GPE: dextran\n",
            "ORG: IL-6\n",
            "ORG: IκBζ\n",
            "ORG: IκBζ\n",
            "ORG: Tet2\n",
            "ORG: Hdac2\n",
            "CARDINAL: transcription\n",
            "DATE: 18 years ago\n",
            "ORG: CoVs\n",
            "GPE: Wuhan\n",
            "GPE: China\n",
            "DATE: December 12th, 2019\n",
            "CARDINAL: 198\n",
            "CARDINAL: three\n",
            "DATE: January 20th, 2020\n",
            "CARDINAL: five\n",
            "PERCENT: 79.5%\n",
            "PERCENT: 96%\n",
            "CARDINAL: seven\n",
            "ORG: CoV\n",
            "PERSON: ACE2\n",
            "PERSON: Chitosan\n",
            "PERSON: Chitosan\n",
            "PERSON: Chitosan\n",
            "GPE: organelle\n",
            "QUANTITY: 2.6 kg h–1\n",
            "CARDINAL: 1\n",
            "PERCENT: 80%\n",
            "PERCENT: 22.5%\n",
            "CARDINAL: 60\n",
            "CARDINAL: 1\n",
            "CARDINAL: 85\n",
            "CARDINAL: 2,000\n",
            "ORG: CT\n",
            "ORG: CFD\n",
            "ORG: CT\n",
            "CARDINAL: 3\n",
            "CARDINAL: 3\n",
            "PERSON: nasal airflow\n",
            "ORG: meatus\n",
            "ORG: PHB\n",
            "PERCENT: 15% to 106%\n",
            "PERCENT: 40% to 60%\n",
            "CARDINAL: 60\n",
            "WORK_OF_ART: Ca/P\n",
            "CARDINAL: 1.66\n",
            "CARDINAL: 1.67\n",
            "NORP: chondrocyte\n",
            "DATE: recent years\n",
            "ORG: BIQA\n",
            "ORG: BIQA\n",
            "CARDINAL: roughly 2x10\n",
            "CARDINAL: 7\n",
            "ORG: ImageNet\n",
            "NORP: BIQA\n",
            "ORG: NP\n",
            "ORG: TSP\n",
            "CARDINAL: three\n",
            "ORG: TSP\n",
            "ORG: CPU\n",
            "ORG: TSP\n",
            "\n",
            " Researcher: 3-Irene Li\n",
            "Named Entities Found (label: text):\n",
            "ORG: Retrieval Augmented Generation\n",
            "ORG: RAG\n",
            "ORG: RAG\n",
            "PERSON: Knowledge Graphs\n",
            "PERSON: Large Language Models\n",
            "PERSON: HealthGenie\n",
            "ORG: KG\n",
            "PERSON: HealthGenie\n",
            "ORG: LLM-KG\n",
            "ORG: LLM\n",
            "ORG: KG\n",
            "ORG: QA\n",
            "NORP: Japanese\n",
            "PERSON: GPT-4\n",
            "ORDINAL: first\n",
            "ORG: KG\n",
            "NORP: Japanese\n",
            "ORG: KG\n",
            "ORG: RAG\n",
            "NORP: Japanese\n",
            "ORG: QA\n",
            "ORG: RAG\n",
            "PERSON: RAG\n",
            "NORP: Japanese\n",
            "ORG: QA\n",
            "PRODUCT: JiraiBench\n",
            "ORDINAL: first\n",
            "NORP: Chinese\n",
            "NORP: Japanese\n",
            "PERSON: Jirai\n",
            "CARDINAL: 10,419\n",
            "NORP: Chinese\n",
            "CARDINAL: 5,000\n",
            "NORP: Japanese\n",
            "CARDINAL: three\n",
            "CARDINAL: four\n",
            "NORP: Japanese\n",
            "NORP: Chinese\n",
            "NORP: Chinese\n",
            "ORG: QA\n",
            "LANGUAGE: English\n",
            "ORG: QA\n",
            "PERSON: Multilingual Knowledge Graph-based\n",
            "PERSON: Retrieval Ranking\n",
            "ORG: MKG-Rank\n",
            "LANGUAGE: English\n",
            "LANGUAGE: English\n",
            "ORG: LLM\n",
            "ORG: QA\n",
            "NORP: Chinese\n",
            "NORP: Japanese\n",
            "NORP: Korean\n",
            "ORG: Swahili\n",
            "ORG: MKG-Rank\n",
            "CARDINAL: zero\n",
            "PERCENT: 35.03%\n",
            "TIME: only 0.0009 seconds\n",
            "CARDINAL: 13\n",
            "CARDINAL: approximately 11,829\n",
            "CARDINAL: 25\n",
            "CARDINAL: 5\n",
            "ORG: CoT\n",
            "CARDINAL: zero\n",
            "PERCENT: 70%\n",
            "LANGUAGE: English\n",
            "PERCENT: around 40%\n",
            "ORG: Swahili\n",
            "ORG: QA\n",
            "ORG: CoT\n",
            "ORG: CoT\n",
            "PERSON: ReAgent\n",
            "ORG: Reversible\n",
            "ORG: QA\n",
            "ORG: QA\n",
            "CARDINAL: three\n",
            "ORG: ReAgent\n",
            "CARDINAL: 6\\%\n",
            "CARDINAL: two\n",
            "CARDINAL: 1\n",
            "CARDINAL: 2\n",
            "ORG: Graph Neural Networks\n",
            "CARDINAL: seven\n",
            "CARDINAL: 6.1\\%\n",
            "PRODUCT: DeepSeek-V3\n",
            "ORG: LUAD\n",
            "CARDINAL: 59’104\n",
            "CARDINAL: 27’280\n",
            "CARDINAL: five\n",
            "NORP: European\n",
            "LANGUAGE: English\n",
            "NORP: French\n",
            "NORP: German\n",
            "NORP: Spanish\n",
            "NORP: Turkish\n",
            "PERCENT: 71%\n",
            "ORG: Mistral\n",
            "PERCENT: 2%\n",
            "PERCENT: 82%\n",
            "ORG: Mistral\n",
            "PERCENT: 78%\n",
            "PERSON: Knowledge Graphs\n",
            "ORG: QA\n",
            "PERSON: KGC\n",
            "GPE: Graphusion\n",
            "CARDINAL: zero\n",
            "ORG: KGC\n",
            "CARDINAL: three\n",
            "ORG: KG\n",
            "CARDINAL: 2\n",
            "CARDINAL: 3\n",
            "GPE: Graphusion\n",
            "CARDINAL: 2.92\n",
            "CARDINAL: 2.37\n",
            "CARDINAL: 3\n",
            "GPE: Graphusion\n",
            "ORG: the Natural Language Processing\n",
            "ORG: NLP\n",
            "ORG: QA\n",
            "CARDINAL: six\n",
            "CARDINAL: 1,200\n",
            "ORG: QA\n",
            "PERCENT: 9.2%\n",
            "PERSON: Language Models~(LLMs\n",
            "ORG: KG\n",
            "ORG: Interaction and Graphical Representation\n",
            "CARDINAL: 3,500\n",
            "CARDINAL: zero\n",
            "CARDINAL: 95.12\\%\n",
            "ORG: AGENTiGraph\n",
            "ORG: Large Language Models\n",
            "ORG: LLM\n",
            "ORG: LLM\n",
            "ORG: LLM\n",
            "ORG: Question Answering\n",
            "ORG: QA\n",
            "ORG: KGC\n",
            "GPE: Graphusion\n",
            "CARDINAL: zero\n",
            "ORG: KGC\n",
            "GPE: Graphusion\n",
            "ORG: NLP\n",
            "ORG: QA\n",
            "CARDINAL: six\n",
            "CARDINAL: 1,200\n",
            "ORG: QA\n",
            "GPE: Graphusion\n",
            "PERCENT: up to 10%\n",
            "CARDINAL: 2.92\n",
            "CARDINAL: 2.37\n",
            "CARDINAL: 3\n",
            "PERSON: Nadal et al.\n",
            "ORG: Journal of Counseling and Development\n",
            "CARDINAL: 57–66\n",
            "DATE: 2014\n",
            "ORG: Pascoe & Smart Richman\n",
            "ORG: Psychological Bulletin\n",
            "CARDINAL: 135\n",
            "CARDINAL: 531\n",
            "DATE: 2009\n",
            "ORG: Sirois & Burg\n",
            "ORG: Behavior Modification\n",
            "DATE: 83–102, 2003\n",
            "ORG: Williams & Mohammed\n",
            "ORG: Journal of Behavioral Medicine\n",
            "CARDINAL: 32\n",
            "DATE: 2009\n",
            "PERSON: Lombardero et al.\n",
            "ORG: Journal of Clinical Psychology\n",
            "CARDINAL: 30\n",
            "CARDINAL: 261–273\n",
            "DATE: 2023\n",
            "ORG: Acceptance and Commitment Training\n",
            "CARDINAL: one\n",
            "PERSON: ARISE\n",
            "ORG: Responsiveness\n",
            "PERSON: Levetiracetam\n",
            "ORDINAL: first\n",
            "CARDINAL: One hundred\n",
            "CARDINAL: 7\n",
            "CARDINAL: 4\n",
            "CARDINAL: Two\n",
            "CARDINAL: three\n",
            "GPE: US\n",
            "GPE: UK\n",
            "PERSON: Cox\n",
            "NORP: infliximab\n",
            "PERSON: vedolizumab\n",
            "DATE: 3+\n",
            "ORDINAL: second\n",
            "ORG: ICI\n",
            "\n",
            " Researcher: 4-Linqi Song\n",
            "Named Entities Found (label: text):\n",
            "PERSON: GPT-4\n",
            "ORG: OpenAI\n",
            "PERSON: GPT-4\n",
            "WORK_OF_ART: GPT-4 Code Interpreter\n",
            "WORK_OF_ART: GPT-4 Code Interpreter\n",
            "WORK_OF_ART: GPT-4 Code Interpreter\n",
            "CARDINAL: zero\n",
            "WORK_OF_ART: GPT-4 Code Interpreter\n",
            "WORK_OF_ART: False\n",
            "ORG: CSV\n",
            "CARDINAL: zero\n",
            "WORK_OF_ART: GPT-4 Code Interpreter\n",
            "ORG: MathCoder\n",
            "ORG: MathCoder\n",
            "PERCENT: 45.2%\n",
            "PERSON: GSM8K\n",
            "PERCENT: 83.9%\n",
            "ORG: MathCoder\n",
            "PERSON: GPT-4\n",
            "DATE: recent years\n",
            "ORG: PIN\n",
            "ORG: CLIP\n",
            "ORG: VLP\n",
            "ORDINAL: first\n",
            "PERSON: Module\n",
            "ORG: CLIP\n",
            "FAC: MoPE\n",
            "ORG: MoPE-CLIP\n",
            "CARDINAL: zero\n",
            "GPE: width\n",
            "CARDINAL: two\n",
            "FAC: MoPE\n",
            "ORG: MoPE-CLIP\n",
            "ORG: VLP\n",
            "ORG: Massive Outliers\n",
            "PERSON: DuQuant\n",
            "ORDINAL: First\n",
            "ORG: DuQuant\n",
            "ORDINAL: Second\n",
            "QUANTITY: 4-bit\n",
            "ORG: FL\n",
            "CARDINAL: three\n",
            "ORDINAL: Firstly\n",
            "ORDINAL: Second\n",
            "ORG: FL\n",
            "ORG: FL\n",
            "ORG: the Age of Information\n",
            "ORG: AoI\n",
            "ORG: IIoT\n",
            "ORG: AoI\n",
            "ORDINAL: first\n",
            "PERSON: Markov\n",
            "ORG: linear programming\n",
            "ORG: AoI\n",
            "CARDINAL: 1\n",
            "CARDINAL: 2\n",
            "PERSON: IoV\n",
            "PERSON: IoV\n",
            "ORG: Personalized Federated Recommendation\n",
            "ORG: GNN\n",
            "DATE: recent years\n",
            "ORG: FL\n",
            "ORG: Adaptive Quantized Gradient\n",
            "ORG: AQG\n",
            "ORG: an Augmented AQG\n",
            "ORG: AQG\n",
            "PERCENT: 18% to 50%\n",
            "ORG: Quantized Gradient Descent\n",
            "PERSON: Lazily Aggregated Quantized\n",
            "ORG: LAQ\n",
            "ORG: AQG\n",
            "PERCENT: up to 90%\n",
            "ORG: FL\n",
            "ORG: RecRanker\n",
            "ORG: Ranker\n",
            "ORG: LLM\n",
            "CARDINAL: three\n",
            "ORG: RecRanker\n",
            "ORG: CAD\n",
            "ORG: SSL\n",
            "ORDINAL: first\n",
            "ORG: CAD\n",
            "ORG: SSL\n",
            "PERCENT: 69.14%\n",
            "PERCENT: 69.65%\n",
            "PERCENT: 72.62%\n",
            "ORG: FV\n",
            "ORG: FVEL\n",
            "ORG: Formal Verification Environment\n",
            "GPE: Isabelle\n",
            "ORG: LLM\n",
            "GPE: Isabelle\n",
            "ORG: FVELER\n",
            "ORG: FVELER\n",
            "GPE: Isabelle\n",
            "CARDINAL: 758\n",
            "CARDINAL: 29,304\n",
            "CARDINAL: 201,498\n",
            "ORG: FVELER\n",
            "ORDINAL: first\n",
            "ORG: FVELER\n",
            "DATE: Code2Inv\n",
            "ORG: SV-COMP\n",
            "ORG: FVELER\n",
            "PERCENT: 17.39%\n",
            "PERCENT: 12%\n",
            "GPE: SV\n",
            "CARDINAL: 1\n",
            "CARDINAL: 2\n",
            "ORDINAL: first\n",
            "ORG: MTL\n",
            "ORG: MTL\n",
            "CARDINAL: 69.48\n",
            "PERCENT: 1.6%\n",
            "CARDINAL: 71.44\n",
            "PERCENT: 3.2%\n",
            "CARDINAL: 83.29\n",
            "PERCENT: 3.2%\n",
            "ORG: MTL\n",
            "PERSON: \\textbf{L}arge \\textbf{la}nguage\n",
            "ORG: LLM\n",
            "ORG: LLM\n",
            "CARDINAL: three\n",
            "ORG: Adaptively-Compressed Stochastic Gradient Descent\n",
            "ORG: the Adaptive Compression Problem\n",
            "ORG: ACP\n",
            "ORG: ACP\n",
            "ORG: AG-News\n",
            "ORG: Upper Confidence Bound\n",
            "CARDINAL: two\n",
            "NORP: Byzantine\n",
            "ORG: Krum\n",
            "NORP: Byzantine\n",
            "ORG: SignGuard\n",
            "NORP: Byzantine\n",
            "ORDINAL: first\n",
            "PERSON: Logit Lens\n",
            "ORG: MHSA\n",
            "ORG: MHSA\n",
            "ORG: CREME\n",
            "\n",
            " Researcher: 5-Thang Vu\n",
            "Named Entities Found (label: text):\n",
            "ORDINAL: First\n",
            "PERSON: Cascade RPN\n",
            "ORDINAL: Second\n",
            "CARDINAL: two\n",
            "ORG: Cascade RPN\n",
            "CARDINAL: 13.4\n",
            "ORG: AR\n",
            "CARDINAL: three\n",
            "ORDINAL: First\n",
            "ORDINAL: Second\n",
            "ORDINAL: Third\n",
            "DATE: 2018\n",
            "ORG: FEQE\n",
            "ORDINAL: first\n",
            "DATE: https://github.com/thangvubk/FEQE.git\n",
            "ORG: IoU\n",
            "ORG: IoU\n",
            "ORG: SCNet\n",
            "ORG: AP\n",
            "ORG: AP\n",
            "CARDINAL: 38\\%\n",
            "ORG: SCNet\n",
            "ORG: AP\n",
            "CARDINAL: 1.3\n",
            "CARDINAL: 2.3\n",
            "PERSON: Cascade Mask R-CNN\n",
            "ORG: C-RAN\n",
            "ORDINAL: First\n",
            "ORG: Rayleigh\n",
            "ORG: BLER\n",
            "\n",
            " Researcher: 6-Nora Hollenstein\n",
            "Named Entities Found (label: text):\n",
            "NORP: Dutch\n",
            "LANGUAGE: English\n",
            "NORP: German\n",
            "NORP: Russian\n",
            "ORG: BERT\n",
            "ORG: XLM\n",
            "ORG: the Shared Task on Eye-Tracking Data Prediction\n",
            "ORDINAL: eleventh\n",
            "ORG: Cognitive Modeling\n",
            "PERSON: Computational Linguistics\n",
            "DATE: CMCL 2021\n",
            "CARDINAL: 5\n",
            "ORG: the Zurich Cognitive Language Processing Corpus\n",
            "ORG: ZuCo\n",
            "NORP: English\n",
            "CARDINAL: 13\n",
            "ORDINAL: first\n",
            "ORG: EEG\n",
            "ORG: EEG\n",
            "ORG: EEG\n",
            "ORG: EEG\n",
            "ORG: BERT\n",
            "ORG: EEG\n",
            "CARDINAL: three-fold\n",
            "LANGUAGE: English\n",
            "ORG: CopCo\n",
            "ORG: the Copenhagen Corpus\n",
            "NORP: Danish\n",
            "ORDINAL: first\n",
            "NORP: Danish\n",
            "ORG: CopCo\n",
            "CARDINAL: 1,832\n",
            "CARDINAL: 34,897\n",
            "NORP: Danish\n",
            "ORDINAL: first\n",
            "CARDINAL: 22\n",
            "ORG: NLP\n",
            "ORG: M/EEG\n",
            "ORG: NLP\n",
            "ORG: NLP\n",
            "ORDINAL: second\n",
            "ORG: the Cognitive Modeling\n",
            "ORG: Computational Linguistics Workshop\n",
            "PERSON: CMCL\n",
            "CARDINAL: six\n",
            "ORDINAL: first\n",
            "ORDINAL: second\n",
            "LANGUAGE: English\n",
            "LANGUAGE: English\n",
            "ORG: NLP\n",
            "ORG: NLP\n",
            "ORG: NLP\n",
            "ORG: NLP\n",
            "PERSON: ScanTextGAN\n",
            "PERSON: ScanTextGAN\n",
            "CARDINAL: four\n",
            "ORG: NLP\n",
            "CARDINAL: six\n",
            "ORG: NLP\n",
            "ORDINAL: first\n",
            "CARDINAL: 10\n",
            "CARDINAL: 15\n",
            "CARDINAL: 3\n",
            "CARDINAL: 0.81\n",
            "CARDINAL: 203.73\n",
            "ORG: ALS\n",
            "ORG: ML\n",
            "ORG: ML\n",
            "ORG: ML\n",
            "CARDINAL: eight\n",
            "ORG: ML\n",
            "ORDINAL: first\n",
            "CARDINAL: 600\n",
            "LANGUAGE: English\n",
            "NORP: German\n",
            "NORP: Spanish\n",
            "NORP: Turkish\n",
            "CARDINAL: two\n",
            "CARDINAL: five\n",
            "CARDINAL: three\n",
            "ORDINAL: first\n",
            "CARDINAL: two\n",
            "ORG: XL\n",
            "ORG: The Zurich Cognitive Language Processing Corpus\n",
            "ORG: ZuCo\n",
            "ORG: EEG\n",
            "CARDINAL: two\n",
            "CARDINAL: two\n",
            "ORG: EEG\n",
            "ORG: ZuCo 2.0\n",
            "ORG: Natural Language Processing\n",
            "ORG: NLP\n",
            "ORG: NLP\n",
            "ORG: NLP\n",
            "ORG: NLP\n",
            "NORP: English\n",
            "CARDINAL: 7129\n",
            "CARDINAL: 400\n",
            "ORG: Zurich Cognitive Language Processing Corpus\n",
            "PERSON: Hollenstein\n",
            "DATE: 2018\n",
            "ORG: linear\n",
            "CARDINAL: 224–304\n",
            "PERSON: phrase-\n",
            "ORG: FRP\n",
            "ORG: FRP\n",
            "CARDINAL: 40\n",
            "CARDINAL: 0.60\n",
            "PERCENT: 95%\n",
            "CARDINAL: 0.58\n",
            "CARDINAL: 0.61\n",
            "ORG: lexico-semantic\n",
            "ORG: lexico-semantic\n",
            "ORG: NLP\n",
            "CARDINAL: two\n",
            "ORG: PLM-AS\n",
            "ORDINAL: first\n",
            "ORG: PLM-AS\n",
            "CARDINAL: three\n",
            "ORG: CGA\n",
            "ORG: VAE\n",
            "ORG: CGA\n",
            "NORP: English\n",
            "ORG: NLP\n",
            "ORG: CGA\n",
            "ORG: NLP\n",
            "ORG: NLP\n",
            "ORDINAL: first\n",
            "ORG: EEG\n",
            "ORG: EEG\n",
            "ORG: EEG\n",
            "CARDINAL: two\n",
            "ORG: EEG\n",
            "ORG: EEG\n",
            "ORG: EEG\n",
            "ORG: EEG\n",
            "ORG: NLP\n",
            "ORG: EEG\n",
            "CARDINAL: between two\n",
            "FAC: the Zurich Cognitive Language Processing Corpus\n",
            "ORG: EEG\n",
            "NORP: English\n",
            "\n",
            " Researcher: 7-Gabriella Lapesa\n",
            "Named Entities Found (label: text):\n",
            "CARDINAL: 1\n",
            "CARDINAL: 2\n",
            "ORG: PositiveModeration\n",
            "WORK_OF_ART: Positive Moderation\n",
            "CARDINAL: 13\n",
            "DATE: LLaMA\n",
            "CARDINAL: 1\n",
            "CARDINAL: 2\n",
            "PERSON: Large Language Models\n",
            "CARDINAL: four\n",
            "ORDINAL: First\n",
            "CARDINAL: nine\n",
            "CARDINAL: two\n",
            "ORG: LLM\n",
            "ORDINAL: first\n",
            "ORDINAL: second\n",
            "CARDINAL: three\n",
            "ORG: LLM\n",
            "CARDINAL: zero\n",
            "CARDINAL: three\n",
            "CARDINAL: 2.500\n",
            "CARDINAL: five\n",
            "CARDINAL: 67.500\n",
            "ORG: LLM\n",
            "ORG: NLP\n",
            "CARDINAL: One\n",
            "CARDINAL: two\n",
            "PERSON: Twitter\n",
            "PERSON: Twitter\n",
            "DATE: years\n",
            "GPE: node\n",
            "PERSON: Kialo\n",
            "ORG: COVID-19\n",
            "CARDINAL: three\n",
            "CARDINAL: 367\n",
            "NORP: Reddit\n",
            "PERSON: COVID\n",
            "CARDINAL: 2015\n",
            "NORP: European\n",
            "NORP: German\n",
            "ORDINAL: First\n",
            "CARDINAL: two\n",
            "LOC: Mediterranean\n",
            "DATE: April/May\n",
            "CARDINAL: one\n",
            "NORP: Balkan\n",
            "DATE: September/October\n",
            "CARDINAL: one\n",
            "NORP: German\n",
            "ORG: NLP\n",
            "NORP: Russian\n",
            "GPE: Russia\n",
            "CARDINAL: three\n",
            "ORDINAL: first\n",
            "NORP: Russian\n",
            "GPE: U.S.\n",
            "GPE: Ukraine\n",
            "GPE: Russia\n",
            "PERSON: Kiezdeutsch\n",
            "NORP: German\n",
            "DATE: recent years\n",
            "ORG: Kiezdeutsch\n",
            "ORDINAL: first\n",
            "CARDINAL: morpho\n",
            "ORG: Kiezdeutsch\n",
            "NORP: German\n",
            "ORG: Integer Linear Programming\n",
            "NORP: German\n",
            "CARDINAL: two\n",
            "ORG: NLP\n",
            "CARDINAL: One\n",
            "CARDINAL: two\n",
            "PERSON: Large Language Models\n",
            "CARDINAL: four\n",
            "ORDINAL: First\n",
            "CARDINAL: nine\n",
            "CARDINAL: two\n",
            "ORG: LLM\n",
            "ORDINAL: first\n",
            "ORDINAL: second\n",
            "CARDINAL: three\n",
            "ORG: LLM\n",
            "CARDINAL: zero\n",
            "CARDINAL: three\n",
            "CARDINAL: 2.500\n",
            "CARDINAL: five\n",
            "CARDINAL: 67.500\n",
            "ORG: LLM\n",
            "CARDINAL: 1\n",
            "CARDINAL: 2\n",
            "ORG: PositiveModeration\n",
            "WORK_OF_ART: Positive Moderation\n",
            "CARDINAL: 13\n",
            "DATE: LLaMA\n",
            "CARDINAL: 1\n",
            "CARDINAL: 2\n",
            "ORG: COVID-19\n",
            "CARDINAL: three\n",
            "CARDINAL: 367\n",
            "NORP: Reddit\n",
            "PERSON: COVID\n",
            "CARDINAL: one\n",
            "ORDINAL: first\n",
            "ORG: GESIS-DSM\n",
            "ORG: the Perspective Argument Retrieval Task\n",
            "PERSON: Large Language Model\n",
            "ORDINAL: third\n",
            "ORG: UMOD\n",
            "ORDINAL: first\n",
            "ORG: UMOD\n",
            "CARDINAL: 1000\n",
            "ORG: UMOD\n",
            "CARDINAL: two\n",
            "ORG: Natural Language Processing\n",
            "ORG: NLP\n",
            "CARDINAL: three\n",
            "CARDINAL: 1\n",
            "ORG: AQ\n",
            "ORG: Argument Mining\n",
            "ORG: Deliberation Theory\n",
            "CARDINAL: 2\n",
            "CARDINAL: 3\n",
            "ORG: AQ\n",
            "ORG: AQ\n",
            "ORG: NLP\n",
            "PERSON: AQ\n",
            "ORG: AQ\n",
            "CARDINAL: two\n",
            "ORG: NLP\n",
            "\n",
            " Researcher: 8-Qiaoqiao She\n",
            "Named Entities Found (label: text):\n",
            "CARDINAL: two\n",
            "CARDINAL: two\n",
            "ORDINAL: first\n",
            "ORG: ICL\n",
            "ORG: NN Prompting\n",
            "ORDINAL: first\n",
            "CARDINAL: two-fold\n",
            "CARDINAL: 1\n",
            "CARDINAL: 2\n",
            "CARDINAL: 10\n",
            "CARDINAL: 2\n",
            "DATE: 1024\n",
            "ORG: LLM\n",
            "ORG: Markdown\n",
            "ORG: HTML\n",
            "PERSON: MMTab\n",
            "CARDINAL: 23\n",
            "ORG: UPainting\n",
            "CARDINAL: 1\n",
            "ORG: UPainting\n",
            "PRODUCT: Transformer\n",
            "ORG: UPainting\n",
            "ORG: UniBench\n",
            "NORP: Chinese\n",
            "NORP: English\n",
            "ORG: UPainting\n",
            "ORG: UPainting\n",
            "NORP: Chinese\n",
            "CARDINAL: more than 90\n",
            "CARDINAL: 8\n",
            "CARDINAL: 1\n",
            "CARDINAL: 2\n",
            "CARDINAL: two\n",
            "GPE: DuReader_retrieval\n",
            "CARDINAL: Tabular\n",
            "ORG: CoT\n",
            "ORG: LLM\n",
            "ORDINAL: first\n",
            "ORG: TaCo\n",
            "CARDINAL: two\n",
            "ORG: CoT\n",
            "ORG: TaCo\n",
            "PERCENT: 9.55%\n",
            "PERCENT: 82.60%→92.15%\n",
            "ORG: QA\n",
            "ORDINAL: first\n",
            "EVENT: Chinese Open\n",
            "ORG: DuReadervis\n",
            "QUANTITY: 158K\n",
            "ORG: Baidu\n",
            "CARDINAL: three\n",
            "PERSON: DuReadervis\n",
            "CARDINAL: 1\n",
            "CARDINAL: 2\n",
            "CARDINAL: 3\n",
            "ORG: Less-Learn-Shortcut\n",
            "ORG: LLS\n",
            "ORG: Question Matching\n",
            "ORG: Natural Language Inference\n",
            "ORG: LLS\n",
            "ORDINAL: firstly\n",
            "ORG: Question Decomposition Meaning Representation\n",
            "PERSON: QDMR\n",
            "ORDINAL: first\n",
            "ORG: LLM\n",
            "PERSON: QDMR\n",
            "ORG: LLM\n",
            "PERSON: QDMR\n",
            "PERSON: QDMR\n",
            "PERSON: QDMR\n",
            "PERSON: QDMR\n",
            "ORG: the Allen Institute\n",
            "ORG: LLM\n",
            "ORG: SIG-TQA\n",
            "ORG: SQL\n",
            "ORG: SQL\n",
            "ORG: SQL\n",
            "ORG: SIG\n",
            "ORG: TQA\n",
            "ORG: SIG\n",
            "ORG: TQA\n",
            "ORG: SIG-TQA\n",
            "ORG: Machine\n",
            "ORG: MRC\n",
            "ORG: NLP\n",
            "ORG: BERT\n",
            "ORG: MRC\n",
            "ORG: BERT\n",
            "ORG: MRC\n",
            "ORG: KT-NET\n",
            "ORG: BERT\n",
            "ORG: KT-NET\n",
            "ORG: BERT\n",
            "ORG: SQuAD1.1\n",
            "ORDINAL: 1st\n",
            "ORG: SQuAD1.1\n",
            "DATE: March 4th, 2019\n",
            "PERSON: DuReader\n",
            "NORP: Chinese\n",
            "ORG: MRC\n",
            "PERSON: DuReader\n",
            "CARDINAL: three\n",
            "ORG: MRC\n",
            "CARDINAL: 1\n",
            "ORG: Baidu Search\n",
            "ORG: Baidu Zhidao\n",
            "CARDINAL: 2\n",
            "CARDINAL: 3\n",
            "CARDINAL: 200\n",
            "CARDINAL: 420\n",
            "NORP: Chinese\n",
            "PERSON: DuReader\n",
            "ORDINAL: first\n",
            "CARDINAL: two\n",
            "\n",
            " Researcher: 9-Ashkan Kazemi\n",
            "Named Entities Found (label: text):\n",
            "CARDINAL: six\n",
            "ORDINAL: first\n",
            "CARDINAL: 17\n",
            "CARDINAL: 10\n",
            "PERSON: Diaspora\n",
            "ORG: Large Language Models\n",
            "ORG: SynDy\n",
            "ORDINAL: first\n",
            "PERSON: Claim Matching\n",
            "WORK_OF_ART: Topical Clustering\n",
            "WORK_OF_ART: Claim Relationship Classification\n",
            "CARDINAL: three\n",
            "ORG: SynDy\n",
            "ORG: Meedan\n",
            "CARDINAL: over 50\n",
            "DATE: annually\n",
            "ORG: WhatsApp\n",
            "ORG: NLP\n",
            "GPE: AI\n",
            "CARDINAL: one\n",
            "ORG: NLP\n",
            "PERSON: Biased\n",
            "PRODUCT: TextRank\n",
            "PERSON: Biased TextRank\n",
            "NORP: non-English\n",
            "CARDINAL: one\n",
            "ORG: WhatsApp\n",
            "ORDINAL: first\n",
            "LANGUAGE: English\n",
            "GPE: Hindi\n",
            "NORP: Bengali\n",
            "ORG: Malayalam\n",
            "GPE: Tamil\n",
            "ORG: LASER\n",
            "ORG: NLP\n",
            "CARDINAL: four\n",
            "LANGUAGE: English\n",
            "LANGUAGE: Spanish\n",
            "NORP: Portuguese\n",
            "ORG: XLM\n",
            "ORG: LaBSE\n",
            "ORG: SBERT\n",
            "PERCENT: 86%\n",
            "CARDINAL: four\n",
            "ORG: NLP\n",
            "CARDINAL: two\n",
            "CARDINAL: 1\n",
            "PERSON: Biased TextRank\n",
            "CARDINAL: 2\n",
            "CARDINAL: two\n",
            "ORG: Objectives\n",
            "ORG: MSCs\n",
            "NORP: Lactobacillus\n",
            "ORG: Trypan\n",
            "ORG: MTT\n",
            "MONEY: 100 µM H2O2\n",
            "ORG: MTT\n",
            "ORG: MIC\n",
            "MONEY: 0.05\n",
            "MONEY: 0.001\n",
            "MONEY: 0.001\n",
            "MONEY: 0.05\n",
            "ORG: LP-MSCs\n",
            "ORG: LC-MSCs\n",
            "ORG: MSCs\n",
            "ORG: TBG\n",
            "ORG: FLAN-T5\n",
            "GPE: Turing\n",
            "ORG: OPT\n",
            "ORG: TBG\n",
            "PERCENT: up to 42%\n",
            "NORP: Pigouvian\n",
            "NORP: Pigouvian\n",
            "ORG: Validation of the Persian\n",
            "EVENT: the \"Phobia of Covid-19\n",
            "ORG: the Islamic Azad University\n",
            "ORDINAL: second\n",
            "CARDINAL: 400\n",
            "GPE: Phobia\n",
            "FAC: Scale Arpaci et al\n",
            "DATE: 2020\n",
            "NORP: Persian\n",
            "GPE: Phobia\n",
            "CARDINAL: two\n",
            "CARDINAL: three\n",
            "ORG: NFI\n",
            "ORG: IFI\n",
            "ORG: CFI\n",
            "ORG: RFI\n",
            "ORG: TLI\n",
            "CARDINAL: 0.9\n",
            "CARDINAL: 0.08\n",
            "CARDINAL: 3\n",
            "NORP: Persian\n",
            "ORG: Fear Scale\n",
            "DATE: 18 years\n",
            "PERSON: Biased TextRank\n",
            "PRODUCT: TextRank\n",
            "PERSON: Biased TextRank\n",
            "DATE: TextRank\n",
            "CARDINAL: two\n",
            "PERSON: Biased TextRank\n",
            "CARDINAL: two\n",
            "ORG: ROUGE\n",
            "PERSON: Biased TextRank\n",
            "ORG: WWTP\n",
            "ORG: SBR\n",
            "ORG: MLE\n",
            "PERSON: Alteimour\n",
            "GPE: Kheine-Arab\n",
            "NORP: Alteimour\n",
            "ORG: SBR\n",
            "ORG: MLE\n",
            "ORG: SBR\n",
            "NORP: Alteimour\n",
            "PERSON: Alteimour WWTP\n",
            "\n",
            " Researcher: 10-Yan Zhang\n",
            "Named Entities Found (label: text):\n",
            "ORG: DsPAN\n",
            "ORDINAL: Firstly\n",
            "ORDINAL: Secondly\n",
            "ORG: PAN\n",
            "ORG: PAN\n",
            "ORG: PAN\n",
            "ORG: PAN\n",
            "ORG: PAN\n",
            "ORG: DsPAN\n",
            "ORG: DsPAN\n",
            "GPE: YOLO\n",
            "CARDINAL: three\n",
            "ORG: NEU\n",
            "ORG: PCB\n",
            "PERCENT: 80.4%\n",
            "PERCENT: 95.8%\n",
            "PERCENT: 76.3%\n",
            "PERCENT: 3.6%\n",
            "PERCENT: 2.1%\n",
            "PERCENT: 3.9%\n",
            "PERSON: YOLOv8\n",
            "ORDINAL: second\n",
            "CARDINAL: thirteen\n",
            "ORG: DsP-YOLO\n",
            "ORDINAL: first\n",
            "ORG: IBD\n",
            "CARDINAL: 41.8\n",
            "CARDINAL: 28.0\n",
            "CARDINAL: 15\n",
            "PERCENT: 22.3–34.0%\n",
            "PERCENT: 8.9–12.4%\n",
            "ORG: IBD\n",
            "ORG: OER\n",
            "ORG: Co/Fe\n",
            "ORG: Ni/Fe\n",
            "CARDINAL: 500 and 1000\n",
            "CARDINAL: 290\n",
            "CARDINAL: 304\n",
            "ORG: XPS\n",
            "GPE: MoNi4\n",
            "CARDINAL: 500\n",
            "CARDINAL: 1.613\n",
            "ORG: IrO2(+)||Pt/C(-\n",
            "DATE: the past decades\n",
            "ORG: NLP\n",
            "CARDINAL: five\n",
            "ORG: Amazon\n",
            "CARDINAL: two\n",
            "CARDINAL: three\n",
            "GPE: Mo2C\n",
            "ORG: EMW\n",
            "ORG: EMW\n",
            "CARDINAL: 20\n",
            "CARDINAL: 1.8\n",
            "QUANTITY: 2 mm\n",
            "CARDINAL: 5.36 GHz\n",
            "ORG: Hydrogel\n",
            "DATE: the past few decades\n",
            "PERSON: hydrogel\n",
            "GPE: hydrogel\n",
            "ORDINAL: first\n",
            "ORG: YAP\n",
            "ORG: future hydrogel\n",
            "PERSON: Mitochondria\n",
            "ORDINAL: fourth\n",
            "ORDINAL: first\n",
            "PERCENT: over 85%\n",
            "CARDINAL: 1000\n",
            "CARDINAL: 740\n",
            "CARDINAL: 5.2\n",
            "CARDINAL: 5.6\n",
            "ORG: EMW\n",
            "CARDINAL: three\n",
            "CARDINAL: three\n",
            "ORG: EMW\n",
            "ORG: EMW\n",
            "GPE: −\n",
            "CARDINAL: 59.09\n",
            "CARDINAL: 6.96 GHz\n",
            "QUANTITY: 1.9 mm\n",
            "PRODUCT: Q235\n",
            "ORG: EMW\n",
            "ORG: EMW\n",
            "ORG: Micro-action-52\n",
            "PRODUCT: MA-52\n",
            "ORG: MANet\n",
            "ORG: MAR\n",
            "PRODUCT: MA-52\n",
            "PRODUCT: MA-52\n",
            "CARDINAL: 52\n",
            "CARDINAL: seven\n",
            "CARDINAL: 205\n",
            "CARDINAL: 22,422\n",
            "ORG: MANet\n",
            "CARDINAL: nine\n",
            "ORG: MANet\n",
            "ORG: TSM\n",
            "ORG: ResNet\n",
            "CARDINAL: one\n",
            "ORG: EDL\n",
            "PERSON: electrolyte additives\n",
            "GPE: Zn\n",
            "ORG: EDL\n",
            "GPE: Zn\n",
            "PERSON: Herein\n",
            "CARDINAL: 15\n",
            "ORG: EDL\n",
            "ORG: SEI\n",
            "ORG: EDL\n",
            "GPE: Zn\n",
            "ORG: SEI\n",
            "ORG: EDL\n",
            "GPE: Zn\n",
            "ORG: SEI\n",
            "GPE: Zn\n",
            "CARDINAL: 2\n",
            "CARDINAL: 0.5\n",
            "GPE: Zn\n",
            "GPE: Zn\n",
            "ORG: V2O5\n",
            "CARDINAL: 5.5\n",
            "CARDINAL: 3.2\n",
            "ORG: EMW\n",
            "CARDINAL: two\n",
            "ORG: hollow sea urchin CoS2\n",
            "CARDINAL: 5.76\n",
            "QUANTITY: 2.12 mm\n",
            "QUANTITY: 1.87 mm\n",
            "PERSON: Background\n",
            "PERSON: Aim\n",
            "Helicobacter\n",
            "GPE: China\n",
            "DATE: the past decades\n",
            "NORP: H.\n",
            "GPE: China\n",
            "DATE: 1990\n",
            "DATE: 2019\n",
            "ORG: PubMed\n",
            "ORG: China National Knowledge Infrastructure\n",
            "PERCENT: 95%\n",
            "CARDINAL: 412\n",
            "CARDINAL: 1 377\n",
            "PERCENT: 44.2%\n",
            "CARDINAL: 95%CI\n",
            "PERCENT: 43.0–45.5%\n",
            "GPE: China\n",
            "CARDINAL: an estimated 589 million\n",
            "ORG: Northwest\n",
            "PERCENT: 51.8%\n",
            "CARDINAL: 95%CI\n",
            "PERCENT: 47.5–56.1%\n",
            "ORG: East\n",
            "PERCENT: 47.7%\n",
            "CARDINAL: 95%CI\n",
            "PERCENT: 45.4–50.0%\n",
            "LOC: Southwest China\n",
            "PERCENT: 46.6%\n",
            "CARDINAL: 95%CI\n",
            "PERCENT: 42.1–51.1%\n",
            "PERCENT: 58.3%\n",
            "CARDINAL: 95%CI\n",
            "PERCENT: 50.7–65.5%\n",
            "PERCENT: 1983–1994 to 40.0%\n",
            "CARDINAL: 95%CI\n",
            "PERCENT: 38.2–41.8%\n",
            "PERCENT: 28.0%\n",
            "CARDINAL: 95%CI\n",
            "PERCENT: 23.9–32.5%\n",
            "PERCENT: 46.1%\n",
            "CARDINAL: 95%CI\n",
            "PERCENT: 44.5–47.6%\n",
            "GPE: China\n",
            "DATE: the past decades\n",
            "PERSON: Targeted H. pylori\n",
            "ORG: Digital\n",
            "ORG: DTN\n",
            "ORG: DTN\n",
            "ORG: DT\n",
            "ORG: DTN\n",
            "WORK_OF_ART: DT\n",
            "ORDINAL: First\n",
            "ORG: DTN\n",
            "ORG: DTN\n",
            "CARDINAL: 6\n",
            "ORG: DTN\n",
            "CARDINAL: half\n",
            "CARDINAL: 2\n",
            "PERSON: IoV\n",
            "ORG: Machine Learning\n",
            "ORG: ML\n",
            "PERSON: IoV\n",
            "ORG: ML\n",
            "PERSON: IoV\n",
            "PERSON: IoV\n",
            "ORG: ML\n",
            "PERSON: IoV\n",
            "CARDINAL: four\n",
            "PERSON: IoV\n",
            "ORDINAL: fourth\n",
            "PERSON: Hippo\n",
            "ORG: RIP\n",
            "ORG: TAZ/YAP\n",
            "PRODUCT: T24\n",
            "ORG: RIP\n",
            "FAC: Seahorse metabolic analyzer\n",
            "ORG: ChIP\n",
            "ORG: H3K18\n",
            "ORG: LCN2\n",
            "PERSON: Hippo\n",
            "ORG: H3K18\n",
            "ORG: Conclusions-CircXRN2\n",
            "ORG: H3K18\n",
            "PERSON: Hippo\n",
            "DATE: the last decades\n",
            "ORG: PS\n",
            "PERCENT: about 40%\n",
            "ORDINAL: first\n",
            "GPE: PE\n",
            "ORG: PS\n",
            "ORG: PE\n",
            "ORG: PS\n",
            "ORG: SII\n",
            "CARDINAL: 8524\n",
            "ORG: the National Health and Nutritional Examination Surveys\n",
            "ORG: NHANES\n",
            "DATE: 2011–2018\n",
            "DATE: December 31, 2019\n",
            "ORG: SII\n",
            "ORG: CVD\n",
            "DATE: 4.58 years\n",
            "CARDINAL: 872\n",
            "ORG: SII\n",
            "ORG: CVD\n",
            "PERCENT: 102%\n",
            "ORG: CVD\n",
            "CARDINAL: one\n",
            "ORG: SII\n",
            "ORG: SII\n",
            "ORG: SII\n",
            "CARDINAL: 5.97\n",
            "CARDINAL: 6.18\n",
            "ORG: SII\n",
            "ORG: HR=0.79\n",
            "CARDINAL: 95%CI=0.64\n",
            "CARDINAL: 95%CI=0.53\n",
            "ORG: SII\n",
            "ORG: HR=1.93\n",
            "ORG: HR=1.93\n",
            "CARDINAL: 95%CI=1.22\n",
            "ORG: CVD\n",
            "ORG: SII\n",
            "CARDINAL: sub-zero\n",
            "CARDINAL: 10,000\n",
            "TIME: 29 hours\n",
            "ORG: −20\n",
            "CARDINAL: 80\n",
            "\n",
            " Researcher: 11-Arjun Reddy Akula\n",
            "Named Entities Found (label: text):\n",
            "ORG: NMN\n",
            "ORG: NMN\n",
            "ORG: NMN\n",
            "ORDINAL: First\n",
            "ORG: NMN\n",
            "PERCENT: up to 75%\n",
            "ORG: NMN\n",
            "GPE: +11.2%\n",
            "ORG: NMN\n",
            "ORG: CLOSURE\n",
            "PRODUCT: NLVR2\n",
            "ORG: CC-Ref+\n",
            "PERCENT: as much as +10.4%\n",
            "ORG: CC-Ref+\n",
            "ORG: UCLA\n",
            "ORG: DisNet\n",
            "CARDINAL: 3000\n",
            "ORG: Artificial Intelligence\n",
            "PERSON: Visual Storytelling\n",
            "ORG: DisNet\n",
            "ORG: Embodied Vision\n",
            "ORG: Language Task Completion\n",
            "ORG: ALFRED\n",
            "ORG: ALFRED\n",
            "GPE: ALFRED\n",
            "ORG: ALFRED-L\n",
            "ORG: ALFRED\n",
            "ORG: Structured Query\n",
            "ORG: SQL\n",
            "GPE: Natural\n",
            "ORG: SQL\n",
            "ORG: SQL\n",
            "ORG: Conditional Random Fields\n",
            "CARDINAL: three\n",
            "ORG: SQL\n",
            "ORG: NLIDB\n",
            "ORG: Computational Paninian Grammar\n",
            "ORG: CPG\n",
            "CARDINAL: two\n",
            "ORG: CPG\n",
            "ORG: Electrical/Electronics\n",
            "ORG: Communication Engineering\n",
            "CARDINAL: ten\n",
            "ORG: VQA\n",
            "ORG: VQA\n",
            "CARDINAL: one\n",
            "ORG: UCLA\n",
            "ORG: VQG\n",
            "ORG: VQA\n",
            "CARDINAL: two\n",
            "CARDINAL: 310\n",
            "PERSON: Visual Storytelling\n",
            "ORG: Multi-Lingual/Task Demonstration Retrieval\n",
            "ORG: Large Language Models\n",
            "PRODUCT: LLMs).Our\n",
            "ORDINAL: first\n",
            "CARDINAL: 81\n",
            "CARDINAL: 8\n",
            "LANGUAGE: English\n",
            "NORP: non-English\n",
            "CARDINAL: more than 130\n",
            "ORG: LLM\n",
            "PERCENT: 83.7%\n",
            "CARDINAL: two\n",
            "ORG: Ref-Adv\n",
            "PERCENT: 12% to 23%\n",
            "CARDINAL: two\n",
            "ORG: ViLBERT\n",
            "ORG: NLIDB\n",
            "CARDINAL: one\n",
            "ORG: NMN\n",
            "ORG: VQA\n",
            "ORG: REF\n",
            "ORG: NMN\n",
            "ORG: NMN\n",
            "ORG: LG-Conv\n",
            "ORG: NMN\n",
            "ORG: VQA\n",
            "ORG: REF\n",
            "ORG: REF\n",
            "ORG: C3-Ref+\n",
            "ORG: NMN\n",
            "ORG: C3-Ref+\n",
            "CARDINAL: One\n",
            "ORG: VQA\n",
            "ORG: VQAG\n",
            "GPE: CrossVQA\n",
            "ORG: VQA\n",
            "PERSON: VQA2\n",
            "ORG: VizWiz\n",
            "ORG: VQA\n",
            "CARDINAL: One\n",
            "ORG: VQA\n",
            "ORG: NSAIDs\n",
            "CARDINAL: 1,3\n",
            "PERSON: aryl hydrazine\n",
            "ORG: Brønsted or Lewis\n",
            "ORG: NMR\n",
            "ORG: NSAIDs\n",
            "CARDINAL: 1,3\n",
            "PERSON: aryl hydrazine\n",
            "ORG: Brønsted or Lewis\n",
            "ORG: NMR\n",
            "ORDINAL: first\n",
            "ORG: VQA\n",
            "ORG: SeBe\n",
            "ORG: Vision-Language\n",
            "ORG: VL\n",
            "ORG: VL\n",
            "CARDINAL: 705\n",
            "DATE: 2115\n",
            "ORG: Average Concept Distance\n",
            "ORG: SoTA\n",
            "\n",
            " Researcher: 12-Saneem Ahmed Chemmengath\n",
            "Named Entities Found (label: text):\n",
            "CARDINAL: one\n",
            "ORG: Bayes\n",
            "ORG: Bayes\n",
            "CARDINAL: two\n",
            "NORP: sparsegen-lin\n",
            "CARDINAL: one\n",
            "ORG: Bayes\n",
            "ORG: Bayes\n",
            "CARDINAL: 0\n",
            "PRODUCT: F-measure\n",
            "CARDINAL: 0\n",
            "ORG: BERT\n",
            "ORG: TableQA\n",
            "ORG: BERT\n",
            "ORG: WikiTQ-TS\n",
            "CARDINAL: five\n",
            "ORG: TableQA\n",
            "CARDINAL: 1\n",
            "ORG: BERT\n",
            "CARDINAL: 2\n",
            "GPE: T5\n",
            "GPE: GPT2\n",
            "CARDINAL: 3\n",
            "ORG: T3QA\n",
            "ORG: TableQA\n",
            "PERSON: Rotten Tomatoes\n",
            "CARDINAL: 1) Correlation\n",
            "CARDINAL: 2\n",
            "CARDINAL: 3\n",
            "CARDINAL: one\n",
            "ORG: Bayes\n",
            "ORG: Bayes\n",
            "ORG: linear\n",
            "ORDINAL: first\n",
            "ORG: AWA\n",
            "ORG: CUB\n",
            "ORG: QA\n",
            "ORG: TextTableQA\n",
            "DATE: recent years\n",
            "CARDINAL: two\n",
            "ORG: MITQA\n",
            "ORG: MITQA\n",
            "ORG: MITQA\n",
            "NORP: HybridQA\n",
            "ORG: EM\n",
            "GPE: F1\n",
            "\n",
            " Researcher: 14-William Merrill\n",
            "Named Entities Found (label: text):\n",
            "PERSON: RWKV-7\n",
            "CARDINAL: 2.9 billion\n",
            "CARDINAL: 3B\n",
            "CARDINAL: 3B\n",
            "LANGUAGE: English\n",
            "ORG: RWKV-7\n",
            "PERSON: RWKV-7\n",
            "PERSON: TC\n",
            "PERSON: RWKV-7\n",
            "CARDINAL: 3.1 trillion\n",
            "CARDINAL: four\n",
            "ORG: RWKV-7\n",
            "MONEY: 0.19 billion to 2.9 billion\n",
            "CARDINAL: 1B\n",
            "CARDINAL: roughly 1.6B\n",
            "PERCENT: 33%\n",
            "CARDINAL: two\n",
            "ORG: ICI\n",
            "CARDINAL: only half\n",
            "PERCENT: 10-40%\n",
            "ORG: ICI\n",
            "GPE: Melanoma\n",
            "DATE: 18 years of age\n",
            "ORG: ICI\n",
            "ORG: The Ohio State University Comprehensive Cancer Center Skin Cancer Clinic\n",
            "DATE: 10 days\n",
            "ORG: CTCAE\n",
            "CARDINAL: 5.0\n",
            "DATE: 12 weeks\n",
            "ORG: ICI\n",
            "DATE: weeks\n",
            "ORG: Response Evaluation Criteria\n",
            "ORG: Solid Tumors\n",
            "PERSON: ANCOM-BC2\n",
            "CARDINAL: 88\n",
            "CARDINAL: 41\n",
            "CARDINAL: 25\n",
            "ORG: RECIST\n",
            "DATE: 6-month\n",
            "PERSON: Grade ≥\n",
            "CARDINAL: 1\n",
            "CARDINAL: 15/41\n",
            "GPE: Intestinimonas\n",
            "CARDINAL: 0.002\n",
            "ORG: Longicatena\n",
            "CARDINAL: 0.003\n",
            "PERSON: Tenericutes\n",
            "CARDINAL: 0.001\n",
            "PERSON: Lachnospira\n",
            "PERSON: NSJ\n",
            "CARDINAL: 0.002\n",
            "GPE: Blautia\n",
            "GPE: Lachnospiraceae\n",
            "CARDINAL: 0.02\n",
            "CARDINAL: 0.02\n",
            "GPE: Lachnospiraceae\n",
            "ORG: CORD-19\n",
            "CARDINAL: 200\n",
            "CARDINAL: three\n",
            "PERSON: GPT-4\n",
            "CARDINAL: at least one\n",
            "PERSON: GPT-4\n",
            "PERCENT: 67%\n",
            "PERCENT: 87%\n",
            "ORG: NLP\n",
            "CARDINAL: two\n",
            "ORG: GSRH\n",
            "DATE: two weeks later\n",
            "CARDINAL: 75\n",
            "ORG: GSRH\n",
            "ORG: SF-12V Physical Functioning and Emotional Health\n",
            "CARDINAL: two\n",
            "ORG: GSRH\n",
            "ORDINAL: first\n",
            "ORDINAL: second\n",
            "CARDINAL: 0.69\n",
            "CARDINAL: 0.85\n",
            "ORG: GSRH\n",
            "ORG: ANOVA, p<0.001)\n",
            "ORG: xylem\n",
            "CARDINAL: 1\n",
            "CARDINAL: 2\n",
            "CARDINAL: 3\n",
            "ORG: N\n",
            "CARDINAL: 2\n",
            "CARDINAL: 3\n",
            "ORG: N\n",
            "CARDINAL: three\n",
            "CARDINAL: 1\n",
            "CARDINAL: 2\n",
            "ORG: N\n",
            "CARDINAL: 3\n",
            "PRODUCT: N. Recent\n",
            "CARDINAL: two\n",
            "ORG: linear\n",
            "ORDINAL: first\n",
            "CARDINAL: zero\n",
            "PERSON: ReCLIP\n",
            "CARDINAL: zero\n",
            "ORG: CLIP\n",
            "ORG: ReC\n",
            "ORG: CLIP\n",
            "ORDINAL: first\n",
            "PERSON: ReCLIP\n",
            "ORG: CLIP\n",
            "ORG: CLIP\n",
            "ORDINAL: second\n",
            "PERSON: ReCLIP\n",
            "CARDINAL: zero\n",
            "PERCENT: as much as 29%\n",
            "ORG: RefGTA\n",
            "PERSON: ReCLIP\n",
            "ORG: ReC\n",
            "PERCENT: 8%\n",
            "ORG: NLP\n",
            "GPE: L≠P\n",
            "ORG: linear\n",
            "DATE: recent years\n",
            "ORG: NLP\n",
            "PERSON: Hahn\n",
            "DATE: 2020\n",
            "PERSON: Hao et al.\n",
            "DATE: 2022\n",
            "ORDINAL: first\n",
            "CARDINAL: two\n",
            "ORDINAL: first\n",
            "CARDINAL: One\n",
            "ORG: Merrill & Sabharwal\n",
            "DATE: 2023\n",
            "ORG: Mamba\n",
            "ORG: SSM\n",
            "ORG: NLP\n",
            "CARDINAL: One\n",
            "PERSON: Chiang\n",
            "DATE: 2023\n",
            "ORDINAL: first\n",
            "ORDINAL: first\n",
            "ORDINAL: first\n",
            "CARDINAL: billions\n",
            "ORG: NLP\n",
            "ORDINAL: first\n",
            "\n",
            " Researcher: 15-Yixin Nie\n",
            "Named Entities Found (label: text):\n",
            "PERSON: Llama 2\n",
            "MONEY: 7 billion\n",
            "CARDINAL: 70 billion\n",
            "PRODUCT: Llama 2-Chat\n",
            "PRODUCT: Llama 2-Chat\n",
            "ORG: NLI\n",
            "ORG: NLI\n",
            "ORG: NLU\n",
            "GPE: Dynabench\n",
            "GPE: Dynabench\n",
            "GPE: Dynabench\n",
            "GPE: Dynabench\n",
            "CARDINAL: four\n",
            "ORG: NLP\n",
            "ORG: Wikipedia\n",
            "CARDINAL: three\n",
            "ORG: IR\n",
            "DATE: vector\n",
            "ORG: NLI\n",
            "ORG: NLI\n",
            "ORG: WordNet\n",
            "ORG: FEVER\n",
            "CARDINAL: 1\n",
            "CARDINAL: 2\n",
            "ORG: WordNet\n",
            "ORG: NLI\n",
            "CARDINAL: 3\n",
            "CARDINAL: three\n",
            "CARDINAL: three\n",
            "ORG: FEVER\n",
            "CARDINAL: two\n",
            "ORG: ECL\n",
            "ORG: ECL\n",
            "ORG: ECL\n",
            "ORG: ECL\n",
            "ORG: ECL\n",
            "ORG: ECL\n",
            "ORG: ECL\n",
            "ORG: VAE\n",
            "CARDINAL: two\n",
            "CARDINAL: 1\n",
            "ORG: VAE\n",
            "CARDINAL: 2\n",
            "ORDINAL: first\n",
            "ORG: 3D\n",
            "TIME: a few seconds\n",
            "ORG: GPU\n",
            "PERSON: Machine Reading\n",
            "ORG: IR\n",
            "ORG: IR\n",
            "ORG: QA\n",
            "ORG: FEVER\n",
            "ORG: HOTPOTQA\n",
            "ORG: Scene-LLM\n",
            "ORG: Large Language Models\n",
            "ORG: 3D\n",
            "ORG: Scene-LLM\n",
            "ORG: Scene-LLM\n",
            "CARDINAL: two\n",
            "CARDINAL: two\n",
            "CARDINAL: two\n",
            "ORG: the EMNLP RepEval 2017\n",
            "ORG: Shared Task (Nangia et al.\n",
            "DATE: 2017\n",
            "PERSON: Bowman et al.\n",
            "DATE: 2015\n",
            "ORG: ECL\n",
            "GPE: Zn\n",
            "GPE: Cu(I\n",
            "GPE: Zn\n",
            "ORG: ECL\n",
            "PERSON: H2O2\n",
            "GPE: Cu(I\n",
            "ORG: ECL\n",
            "GPE: Cu(I\n",
            "GPE: Cu(I\n",
            "GPE: Cu(I\n",
            "PERSON: H2O2\n",
            "GPE: Zn\n",
            "CARDINAL: 4.5-fold\n",
            "GPE: Cu(I\n",
            "CARDINAL: T7\n",
            "QUANTITY: 0.1 nmol L−1 to 200 nmol L−1\n",
            "ORG: LOD\n",
            "CARDINAL: 0.03\n",
            "PERSON: nmol L−1\n",
            "ORG: ECL\n",
            "ORG: HPV\n",
            "CARDINAL: 16\n",
            "DATE: recent years\n",
            "ORG: LFM\n",
            "CARDINAL: one\n",
            "ORG: NLP\n",
            "ORG: NLU\n",
            "PERSON: ChaosNLI\n",
            "CARDINAL: 464,500\n",
            "PERSON: Collective\n",
            "ORG: NLI\n",
            "QUANTITY: 100 annotations\n",
            "CARDINAL: 3,113\n",
            "LOC: SNLI\n",
            "ORG: MNLI\n",
            "CARDINAL: 1,532\n",
            "LAW: Abductive-NLI\n",
            "CARDINAL: 1\n",
            "CARDINAL: 2\n",
            "CARDINAL: 3\n",
            "ORG: Success\n",
            "ORG: NLI\n",
            "CARDINAL: one\n",
            "ORG: NLI\n",
            "ORG: the Textless Vision-Language Transformer\n",
            "ORG: TVLT\n",
            "CARDINAL: 28x\n",
            "CARDINAL: only 1/3\n",
            "ORG: COntradiction DEtection\n",
            "ORG: Transformer\n",
            "ORG: NLI\n",
            "DATE: recent years\n",
            "CARDINAL: two\n",
            "ORDINAL: first\n",
            "ORG: Nonmetallic\n",
            "ORG: SPC\n",
            "PERSON: Herein\n",
            "ORG: the nonmetallic plasmonic MoS2 nanosheets\n",
            "ORG: ECL\n",
            "ORG: S-BN\n",
            "ORG: ECL\n",
            "ORG: ECL\n",
            "ORG: ECL\n",
            "ORG: HCR\n",
            "ORG: ECL\n",
            "ORG: SPC-ECL\n",
            "CARDINAL: 0.5\n",
            "ORG: LOD\n",
            "CARDINAL: 0.17\n",
            "ORG: ECL\n",
            "PERSON: MXene\n",
            "PERSON: MXene\n",
            "PERSON: MXene\n",
            "ORG: GSH\n",
            "ORG: ECL\n",
            "CARDINAL: T7\n",
            "ORG: GSH-MQD\n",
            "PERSON: MUC1\n",
            "DATE: Faraday\n",
            "ORG: Helmholtz\n",
            "ORG: ECL\n",
            "PERSON: lthough graphite\n",
            "ORG: ECL\n",
            "ORG: ECL\n",
            "PERSON: Herein\n",
            "ORG: S-GCN QDs\n",
            "ORG: ECL\n",
            "ORG: SPC-ECL\n",
            "ORG: ECL\n",
            "ORG: S-GCN QDs\n",
            "CARDINAL: 2.5×\n",
            "ORG: GCN\n",
            "ORG: ECL\n",
            "ORG: GCN\n",
            "CARDINAL: 620\n",
            "GPE: Au NPs\n",
            "ORG: S-GCN QDs\n",
            "ORG: ECL\n",
            "CARDINAL: 555\n",
            "GPE: Au NPs\n",
            "CARDINAL: 530\n",
            "ORG: ECL\n",
            "ORG: S-GCN\n",
            "CARDINAL: 555\n",
            "ORG: K-RAS\n",
            "DATE: 50 fM to 1 nM\n",
            "ORG: LOD\n",
            "CARDINAL: 16\n",
            "ORDINAL: first\n",
            "ORG: ECL\n",
            "\n",
            " Researcher: 13-Urmish Thakker\n",
            "Named Entities Found (label: text):\n",
            "PERSON: Raspberry Pi\n",
            "ORG: IoT\n",
            "ORDINAL: first\n",
            "ORG: FL\n",
            "ORG: IoT\n",
            "ORG: FL\n",
            "ORG: IoT\n",
            "ORG: FL\n",
            "ORG: IoT\n",
            "ORG: FL\n",
            "ORG: IoT\n",
            "ORG: PromptSource\n",
            "ORG: NLP\n",
            "ORG: PromptSource\n",
            "CARDINAL: 1\n",
            "CARDINAL: 2\n",
            "CARDINAL: 3\n",
            "CARDINAL: Over 2,000\n",
            "CARDINAL: roughly 170\n",
            "ORG: PromptSource\n",
            "PERSON: MLPerf Tiny\n",
            "ORDINAL: first\n",
            "CARDINAL: more than 50\n",
            "ORG: MLPerf Tiny\n",
            "PERSON: MLPerf Tiny\n",
            "ORG: ML\n",
            "CARDINAL: four\n",
            "CARDINAL: One\n",
            "PRODUCT: LLM\n",
            "CARDINAL: 9\n",
            "CARDINAL: 2\n",
            "CARDINAL: 7B\n",
            "PRODUCT: Llama 2\n",
            "ORG: XGLM\n",
            "ORG: NAS\n",
            "ORG: ML\n",
            "ORG: MCU\n",
            "ORG: NAS\n",
            "ORG: MCU\n",
            "ORG: NAS\n",
            "ORG: MCU\n",
            "ORG: NAS\n",
            "ORG: MicroNet\n",
            "ORG: Tensorflow Lite Micro\n",
            "CARDINAL: three\n",
            "PERSON: keyword\n",
            "ORG: Alpaca-Eval 2.0\n",
            "ORG: Arena-Hard v0.1\n",
            "DATE: 1573\n",
            "CARDINAL: 14\n",
            "CARDINAL: 84\\%\n",
            "CARDINAL: ten\n",
            "PERSON: Chatbot Arena\n",
            "CARDINAL: 0.915\n",
            "CARDINAL: 9\\%\n",
            "ORG: Arena Hard\n",
            "CARDINAL: 20\\%\n",
            "CARDINAL: 2.0\n",
            "NORP: Spearman\n",
            "CARDINAL: 0.7\n",
            "PERSON: GPT-4\n",
            "GPE: AI\n",
            "GPE: AI\n",
            "GPE: AI\n",
            "ORG: Composition of Experts\n",
            "ORG: CoE\n",
            "CARDINAL: two\n",
            "CARDINAL: 1\n",
            "CARDINAL: 2\n",
            "ORG: CoE\n",
            "CARDINAL: three\n",
            "GPE: AI\n",
            "ORG: Samba-CoE\n",
            "ORG: CoE\n",
            "CARDINAL: 150\n",
            "ORG: Samba-CoE\n",
            "ORG: SambaNova\n",
            "ORG: Reconfigurable Dataflow Unit\n",
            "CARDINAL: three\n",
            "ORG: SRAM\n",
            "ORG: HBM\n",
            "ORG: DDR DRAM\n",
            "CARDINAL: 13×\n",
            "CARDINAL: eight\n",
            "ORG: CoE\n",
            "CARDINAL: 8\n",
            "ORG: Node\n",
            "CARDINAL: up to 19\n",
            "CARDINAL: 15× to\n",
            "CARDINAL: 31×\n",
            "CARDINAL: 3.7×\n",
            "ORG: DGX\n",
            "PRODUCT: H100\n",
            "ORG: DGX\n",
            "CARDINAL: A100\n",
            "CARDINAL: zero\n",
            "PERSON: Brown et al.\n",
            "DATE: 2020\n",
            "DATE: 2019\n",
            "CARDINAL: zero\n",
            "PERSON: Raffel\n",
            "DATE: 2020\n",
            "GPE: Lester\n",
            "DATE: 2021\n",
            "CARDINAL: zero\n",
            "CARDINAL: 16x\n",
            "ORG: GPT\n",
            "ORG: GPT\n",
            "DATE: 13B\n",
            "ORG: GPT\n",
            "CARDINAL: 13B\n",
            "CARDINAL: 4.5x\n",
            "QUANTITY: A100 baseline\n",
            "LANGUAGE: English\n",
            "PERSON: Adapting\n",
            "ORG: LLM\n",
            "LANGUAGE: English\n",
            "NORP: Hungarian\n",
            "NORP: Thai\n",
            "LANGUAGE: English\n",
            "ORG: IoT\n",
            "ORG: ML\n",
            "ORG: ML\n",
            "ORG: FL\n",
            "ORDINAL: first\n",
            "ORG: IoT\n",
            "ORG: FL\n",
            "ORG: FL\n",
            "ORG: NLP\n",
            "GPE: AI\n",
            "CARDINAL: six\n",
            "CARDINAL: 128\n",
            "ORG: Self-Attention Guided\n",
            "CARDINAL: one\n",
            "ORG: LongBench\n",
            "CARDINAL: three\n",
            "CARDINAL: 4x\n",
            "PRODUCT: StreamLLM\n",
            "CARDINAL: 2x\n",
            "LOC: Quest\n",
            "ORG: Kronecker\n",
            "GPE: KP\n",
            "ORG: CMA\n",
            "ORG: CMR\n",
            "ORG: Kronecker Product\n",
            "ORG: LMF\n",
            "WORK_OF_ART: Hybrid Matrix Decomposition\n",
            "DATE: − 25x\n",
            "CARDINAL: 4\n",
            "PERSON: Doped KP\n",
            "CARDINAL: 1.3−2.4x\n",
            "PERCENT: 8%\n",
            "GPE: KP\n",
            "CARDINAL: 2.5\n",
            "ORG: − 5.5x\n",
            "ORG: Kronecker\n",
            "GPE: KP\n",
            "ORG: RNN\n",
            "CARDINAL: 16× to 38×\n",
            "CARDINAL: 8\n",
            "CARDINAL: 50×.\n",
            "GPE: KP\n",
            "CARDINAL: seven\n",
            "CARDINAL: five\n",
            "GPE: KP\n",
            "GPE: KP\n",
            "GPE: KP\n",
            "ORG: KP\n",
            "ORG: Function Calling, Biology\n",
            "NORP: Chinese\n",
            "PERCENT: 11% to 25%\n",
            "PERCENT: 2% to 10%\n",
            "PERCENT: 80% to 93%\n",
            "GPE: SubgoalXL\n",
            "PERSON: SubgoalXL\n",
            "CARDINAL: two\n",
            "ORG: SubgoalXL\n",
            "CARDINAL: 4.9\\%\n",
            "CARDINAL: 41\n",
            "CARDINAL: 9\n",
            "CARDINAL: 3\n",
            "GPE: AI\n",
            "PERSON: Monolithic\n",
            "ORG: CoE\n",
            "ORG: CoE\n",
            "ORG: SambaNova\n",
            "ORG: Reconfigurable Dataflow Unit\n",
            "CARDINAL: three\n",
            "ORG: RAM\n",
            "ORG: RAM\n",
            "CARDINAL: eight\n",
            "ORG: node\n",
            "CARDINAL: 2\n",
            "CARDINAL: 13×\n",
            "ORG: Samba-CoE\n",
            "MONEY: 1 trillion\n",
            "ORG: CoE\n",
            "CARDINAL: 19×\n",
            "CARDINAL: 15–31×\n",
            "CARDINAL: 3.7×\n",
            "ORG: DGX\n",
            "PRODUCT: H100\n",
            "ORG: DGX\n",
            "CARDINAL: A100\n",
            "ORG: Kronecker\n",
            "GPE: KP\n",
            "ORG: CMA\n",
            "ORG: CMR\n",
            "ORG: Kronecker Product\n",
            "ORG: LMF\n",
            "WORK_OF_ART: Hybrid Matrix Decomposition\n",
            "DATE: 10 - 25x\n",
            "CARDINAL: 4\n",
            "PERSON: Doped KP\n",
            "QUANTITY: 1.3 - 2.4x\n",
            "PERCENT: 8%\n",
            "GPE: KP\n",
            "CARDINAL: 2.5\n",
            "ORG: OFM\n",
            "CARDINAL: one\n",
            "ORG: OFM\n",
            "FAC: Precision Gating\n",
            "ORG: OFM\n",
            "ORG: OFM\n",
            "ORG: MAC\n",
            "PERSON: This Hybrid Model\n",
            "CARDINAL: 1.92x\n",
            "PERCENT: 91.35%\n",
            "PERCENT: 89.9%\n",
            "ORG: CPU\n",
            "\n",
            " Researcher: 16-Zhiqing Sun\n",
            "Named Entities Found (label: text):\n",
            "ORG: PDA\n",
            "PERSON: Herein\n",
            "CARDINAL: three\n",
            "ORDINAL: first\n",
            "PERSON: silica\n",
            "CARDINAL: two\n",
            "CARDINAL: six\n",
            "ORG: Large Language Models\n",
            "ORG: AI\n",
            "PERSON: GPT-4\n",
            "ORG: OpenAI Deep Research\n",
            "ORG: Artificial General Intelligence\n",
            "ORG: AGI\n",
            "ORG: SFT\n",
            "ORG: Principle-Driven Alignment\n",
            "GPE: AI\n",
            "ORG: Lean-STaR\n",
            "GPE: AI\n",
            "ORG: AI\n",
            "ORG: AI\n",
            "ORG: the Generalized Suffix Tree\n",
            "PERSON: Color Size Set\n",
            "ORG: Keyword\n",
            "Signature Tree\n",
            "ORG: IDS\n",
            "ORG: RotatE\n",
            "ORG: DETR\n",
            "ORG: Transformer\n",
            "ORG: DETR\n",
            "ORG: DETR\n",
            "NORP: Hungarian\n",
            "ORG: Transformer\n",
            "CARDINAL: two\n",
            "ORG: SFT\n",
            "GPE: AI\n",
            "GPE: AI\n",
            "CARDINAL: four\n",
            "ORDINAL: first\n",
            "ORG: LLM\n",
            "ORDINAL: second\n",
            "ORG: AI\n",
            "ORG: LLM\n",
            "ORDINAL: third\n",
            "PRODUCT: LLM\n",
            "ORG: AI\n",
            "CARDINAL: fewer than 300\n",
            "CARDINAL: 200\n",
            "CARDINAL: 16\n",
            "CARDINAL: 5\n",
            "ORG: AI\n",
            "ORG: Text-Davinci-003\n",
            "GPE: Alpaca\n",
            "NORP: FLARE\n",
            "CARDINAL: 4\n",
            "ORG: LMM\n",
            "CARDINAL: two\n",
            "ORG: the Reinforcement Learning from Human Feedback\n",
            "CARDINAL: two\n",
            "ORG: Factually Augmented\n",
            "ORG: RLHF\n",
            "PERSON: GPT-4\n",
            "ORDINAL: first\n",
            "ORG: LMM\n",
            "ORG: RLHF\n",
            "PERCENT: 94%\n",
            "PERSON: GPT-4\n",
            "PERCENT: 87%\n",
            "PERCENT: 60%\n",
            "ORG: Natural Language Processing\n",
            "ORG: NLP\n",
            "MONEY: hundreds of millions\n",
            "ORG: MobileBERT\n",
            "ORG: BERT\n",
            "ORG: BERT\n",
            "ORG: MobileBERT\n",
            "ORG: NLP\n",
            "ORG: MobileBERT\n",
            "ORG: MobileBERT\n",
            "ORDINAL: first\n",
            "ORG: MobileBERT\n",
            "ORG: MobileBERT\n",
            "CARDINAL: 4.3x\n",
            "GPE: 5.5x\n",
            "GPE: BERT_BASE\n",
            "ORG: GLUE\n",
            "ORG: MobileBERT\n",
            "ORG: GLUEscore\n",
            "CARDINAL: 77.7\n",
            "CARDINAL: 0.6\n",
            "GPE: BERT_BASE\n",
            "CARDINAL: 62\n",
            "LAW: Pixel 4\n",
            "ORG: MobileBERT\n",
            "GPE: F1\n",
            "CARDINAL: 90.0/79.2\n",
            "CARDINAL: 1.5/2.1\n",
            "GPE: BERT_BASE\n",
            "ORG: PromptSource\n",
            "ORG: NLP\n",
            "ORG: PromptSource\n",
            "CARDINAL: 1\n",
            "CARDINAL: 2\n",
            "CARDINAL: 3\n",
            "CARDINAL: Over 2,000\n",
            "CARDINAL: roughly 170\n",
            "ORG: PromptSource Neural\n",
            "ORG: Combinatorial Optimization (CO\n",
            "ORG: NP\n",
            "ORG: NPC\n",
            "ORG: NPC\n",
            "ORG: DIFUSCO\n",
            "ORG: NPC\n",
            "CARDINAL: 0\n",
            "PERSON: Gaussian\n",
            "PERSON: Bernoulli\n",
            "CARDINAL: two\n",
            "ORG: Maximal Independent Set\n",
            "ORG: MIS\n",
            "ORG: DIFUSCO\n",
            "PERCENT: 1.76%\n",
            "PERCENT: 0.46%\n",
            "PERCENT: 2.46% to\n",
            "PERCENT: 1.17%\n",
            "CARDINAL: TSP-1000\n",
            "PERCENT: 3.19% to\n",
            "PERCENT: 2.58%\n",
            "CARDINAL: TSP-10000\n",
            "ORG: MIS\n",
            "PERSON: Large Language Models\n",
            "ORDINAL: first\n",
            "CARDINAL: one\n",
            "ORG: RECITE\n",
            "ORG: NLP\n",
            "CARDINAL: \\method\n",
            "CARDINAL: four\n",
            "ORG: PaLM\n",
            "ORG: OPT\n",
            "CARDINAL: three\n",
            "CARDINAL: two\n",
            "GPE: Nash\n",
            "PERSON: Nash\n",
            "CARDINAL: only 60k\n",
            "ORG: UltraFeedback\n",
            "ORG: PairRM\n",
            "ORG: SPPO\n",
            "PERCENT: 28.53%\n",
            "PERSON: GPT-4-Turbo\n",
            "CARDINAL: 2.0\n",
            "ORG: DPO\n",
            "ORG: IPO\n",
            "ORG: MT-Bench\n",
            "ORG: Arena-Hard\n",
            "EVENT: the Open LLM Leaderboard\n",
            "PERCENT: 38.77%\n",
            "ORG: SPPO\n",
            "PERSON: GPT-4\n",
            "ORG: DRL\n",
            "ORG: NP\n",
            "ORG: Combinatorial Optimization (CO\n",
            "ORG: DRL\n",
            "CARDINAL: a few hundreds\n",
            "ORG: the Traveling Salesman Problem\n",
            "ORG: DIMES\n",
            "ORG: DRL\n",
            "ORG: DIMES\n",
            "ORG: REINFORCE\n",
            "ORG: DRL\n",
            "WORK_OF_ART: Traveling Salesman Problems\n",
            "ORG: Transformer\n",
            "ORG: Transformer\n",
            "ORG: Transformer\n",
            "ORG: Ordinary Differential Equation\n",
            "ORG: Transformer\n",
            "FAC: the Lie-Trotter\n",
            "PERSON: Euler\n",
            "ORG: ODE\n",
            "ORG: Transformer\n",
            "FAC: the Strang-Marchuk\n",
            "FAC: The Strang-Marchuk\n",
            "ORG: FFN\n",
            "CARDINAL: two\n",
            "ORG: FFN\n",
            "ORG: FFN\n",
            "ORG: the Macaron Net\n",
            "ORG: the Macaron Net\n",
            "ORG: Transformer\n",
            "ORG: Knowledge Graph Completion\n",
            "ORG: KGC\n",
            "ORG: KGC\n",
            "ORG: AI\n",
            "CARDINAL: 4\n",
            "CARDINAL: 1\n",
            "ORDINAL: firstly\n",
            "CARDINAL: 1-3\n",
            "PERSON: RL\n",
            "CARDINAL: 7b\n",
            "PERSON: RL\n",
            "CARDINAL: 34b\n",
            "PERCENT: 34.0%\n",
            "PERCENT: 52.5%\n",
            "GPE: AI\n",
            "ORG: Conditional Random Fields\n",
            "ORG: CRF\n",
            "LAW: 8~14ms\n",
            "FAC: the WMT14 En-De\n",
            "ORG: BLEU\n",
            "CARDINAL: 26.80\n",
            "CARDINAL: only 0.61\n",
            "ORG: BLEU\n",
            "ORG: Lean-STaR\n",
            "ORG: Lean-STaR\n",
            "NORP: Lean\n",
            "ORG: Lean-STaR\n",
            "NORP: Lean\n",
            "ORDINAL: first\n",
            "ORG: CNN-BiGRU\n",
            "ORG: CNN\n",
            "GPE: New Zealand\n",
            "GPE: Zhejiang\n",
            "GPE: China\n",
            " No 'Abstract' column in: Author_Profile\n",
            "\n",
            " Researcher: 17-Jinhua Du\n",
            "Named Entities Found (label: text):\n",
            "PERSON: Herein\n",
            "DATE: daytime\n",
            "GPE: ~4\n",
            "ORG: EMPA\n",
            "CARDINAL: 1\n",
            "ORG: EMPA\n",
            "CARDINAL: 19\n",
            "CARDINAL: 0.05\n",
            "ORG: EMPA\n",
            "GPE: China\n",
            "LOC: the Tengger Desert\n",
            "PERSON: Quaternary\n",
            "CARDINAL: 91\n",
            "ORG: OSL\n",
            "CARDINAL: 13–10\n",
            "LOC: the East Asia\n",
            "ORG: EASM\n",
            "CARDINAL: between 7 and 3\n",
            "CARDINAL: two\n",
            "DATE: winter\n",
            "ORG: Holocene\n",
            "NORP: Chinese\n",
            "PERSON: Holocene EAWM\n",
            "CARDINAL: three\n",
            "EVENT: the Chinese Loess Plateau\n",
            "PERSON: Holocene\n",
            "CARDINAL: 11.7–6.5\n",
            "PERSON: Holocene\n",
            "CARDINAL: 6.5\n",
            "LOC: Northern Hemisphere\n",
            "LOC: Northern Hemisphere\n",
            "NORP: East Asian\n",
            "DATE: summer\n",
            "PERSON: Holocene\n",
            "DATE: 2006\n",
            "PERSON: NGs\n",
            "ORG: NG\n",
            "ORG: NG\n",
            "ORG: Light\n",
            "ORG: ISO\n",
            "CARDINAL: between zero\n",
            "ORG: ISO\n",
            "ORG: ISO\n",
            "CARDINAL: zero\n",
            "CARDINAL: 10–20\n",
            "PERSON: ISO\n",
            "ORG: ISO\n",
            "ORG: ISO\n",
            "CARDINAL: 12:00–14:00\n",
            "TIME: night\n",
            "TIME: the morning\n",
            "DATE: the next day\n",
            "ORG: ISO\n",
            "PERCENT: 90–130%\n",
            "DATE: 1–30 days\n",
            "GPE: BVOC\n",
            "GPE: BVOC\n",
            "ORG: Electron\n",
            "ORG: EPR\n",
            "ORG: UVsingle\n",
            "ORG: OV\n",
            "ORG: OV\n",
            "ORG: Wrec of ∼5.6 J\n",
            "PERCENT: 70.1%\n",
            "QUANTITY: 300 kV/cm\n",
            "ORG: AFE\n",
            "ORG: Neural Theory-of-Mind (N-ToM\n",
            "ORG: N-ToM\n",
            "CARDINAL: 1\n",
            "CARDINAL: 2\n",
            "CARDINAL: 3\n",
            "CARDINAL: 4\n",
            "ORG: Pickering\n",
            "ORG: pectin\n",
            "ORG: HP\n",
            "ORG: HP\n",
            "ORG: zein-HP\n",
            "PERSON: ZHPs\n",
            "ORG: ZHP\n",
            "PRODUCT: HP-ZP\n",
            "CARDINAL: 1:1\n",
            "CARDINAL: 92.9o ±\n",
            "CARDINAL: 1.01\n",
            "ORG: Pickering\n",
            "ORG: 0.5–0.7\n",
            "CARDINAL: 0.6\n",
            "ORG: HP\n",
            "ORG: Pickering\n",
            "ORG: Pickering\n",
            "LOC: the East Asia\n",
            "LOC: the East Gobi Desert\n",
            "ORG: DEM\n",
            "CARDINAL: 15,500\n",
            "NORP: Marine\n",
            "CARDINAL: 5\n",
            "QUANTITY: 800–1000 km\n",
            "LOC: East China\n",
            "FAC: the Gobi Desert\n",
            "CARDINAL: 5\n",
            "CARDINAL: 4\n",
            "LOC: East Asia\n",
            "LOC: the North Pacific\n",
            "ORDINAL: second\n",
            "PERSON: albeit smaller\n",
            "ORG: the East Asian Summer Monsoon\n",
            "ORG: EASM\n",
            "CARDINAL: 3\n",
            "ORG: pectin\n",
            "ORG: pectin\n",
            "ORG: pectin\n",
            "ORG: PME\n",
            "ORG: PME\n",
            "ORG: PL\n",
            "PERCENT: 3.41–5.84%\n",
            "ORG: PME\n",
            "PERCENT: 9.46–17.71%\n",
            "PERCENT: 9.17–10.31%\n",
            "DATE: 30 days\n",
            "CARDINAL: three\n",
            "CARDINAL: 4 °\n",
            "ORG: PME\n",
            "ORG: PL\n",
            "QUANTITY: 3.07 kDa\n",
            "ORG: I & CaCl2\n",
            "CARDINAL: 160.69\n",
            "CARDINAL: 95.47\n",
            "CARDINAL: 107.03\n",
            "ORG: S.\n",
            "ORG: pectin\n",
            "CARDINAL: lower than\n",
            "PERSON: kDa\n",
            "CARDINAL: 53.65\n",
            "PRODUCT: Saccharomyces\n",
            "CARDINAL: 136\n",
            "ORDINAL: first\n",
            "CARDINAL: four\n",
            "CARDINAL: 7.89\n",
            "ORG: MLF\n",
            "CARDINAL: 3880.52\n",
            "CARDINAL: 4787.55\n",
            "CARDINAL: 2171.14\n",
            "CARDINAL: 701.51\n",
            "CARDINAL: 8.06\n",
            "CARDINAL: 7.50\n",
            "ORG: CFU\n",
            "DATE: the 5th day\n",
            "ORG: acetaldehyde\n",
            "PERSON: Rahnella\n",
            "NORP: non-Saccharomyces\n",
            "ORG: acetaldehyde\n",
            "CARDINAL: 3\n",
            "ORG: Leuconostoc\n",
            "PERSON: Herein\n",
            "CARDINAL: nearly zero\n",
            "ORG: PLZT\n",
            "ORG: PLZT-TENG\n",
            "ORG: PLZT\n",
            "CARDINAL: 13.5\n",
            "CARDINAL: 1.6-fold\n",
            "ORG: TENG\n",
            "ORG: PZT\n",
            "ORG: PLZT\n",
            "DATE: winter\n",
            "LOC: East Asia\n",
            "CARDINAL: four\n",
            "EVENT: the Chinese Loess Plateau\n",
            "DATE: the mid-1980s\n",
            "DATE: under 21st century\n",
            "ORG: EC\n",
            "PERSON: Herein\n",
            "ORG: EC\n",
            "CARDINAL: 1\n",
            "GPE: KNLNT\n",
            "ORG: ΔT\n",
            "ORG: KNLNT–12CZ\n",
            "ORG: ∼5\n",
            "CARDINAL: 30\n",
            "PERSON: KNLNT–12CZ\n",
            "ORG: Tspan\n",
            "CARDINAL: 65\n",
            "ORG: ΔT\n",
            "CARDINAL: 3.2\n",
            "CARDINAL: 30\n",
            "ORG: EC\n",
            "ORG: EC\n",
            "ORG: EC\n",
            "DATE: daily\n",
            "FAC: OC\n",
            "ORG: EC\n",
            "GPE: Qingdao\n",
            "GPE: China\n",
            "DATE: autumn\n",
            "DATE: Nov. 2017\n",
            "DATE: Jan. 2023\n",
            "DATE: OC\n",
            "ORG: EC\n",
            "GPE: China\n",
            "ORG: COVID-19\n",
            "ORG: EC\n",
            "CARDINAL: 8.28\n",
            "CARDINAL: 4.59\n",
            "ORG: m−3\n",
            "CARDINAL: 2.00\n",
            "CARDINAL: 1.17\n",
            "CARDINAL: 6.34\n",
            "CARDINAL: 3.82\n",
            "CARDINAL: 1.87\n",
            "CARDINAL: 1.01\n",
            "ORG: The XGBoost-SHAP\n",
            "FAC: OC\n",
            "ORG: EC\n",
            "FAC: OC\n",
            "ORG: EC\n",
            "DATE: winter\n",
            "ORG: eastern\n",
            "GPE: Shandong\n",
            "GPE: Qingdao\n",
            "PERCENT: 54.75%–81.78%\n",
            "PERCENT: 8.72%–28.73%\n",
            "PERSON: COVID-19\n",
            "FAC: OC\n",
            "ORG: EC\n",
            "PERCENT: 19%\n",
            "ORG: COVID-19\n",
            "PERCENT: 110%\n",
            "FAC: OC\n",
            "ORG: EC\n",
            "GPE: PM1\n",
            "ORG: Graph Neural Networks\n",
            "ORG: Knowledge Graph Completion\n",
            "ORG: KGC\n",
            "DATE: recent years\n",
            "ORG: GNN\n",
            "ORG: KGC\n",
            "PERSON: KGC\n",
            "ORDINAL: first\n",
            "PERSON: KGC\n",
            "ORG: GNN\n",
            "CARDINAL: three\n",
            "ORG: LMZ\n",
            "CARDINAL: 4\n",
            "CARDINAL: 3.5\n",
            "CARDINAL: 4.2\n",
            "PERCENT: 75.2%\n",
            "GPE: Zaozhuang\n",
            "GPE: Jiangsu\n",
            "GPE: Shandong\n",
            "GPE: Henan\n",
            "GPE: Anhui\n",
            "GPE: Zaozhuang\n",
            "DATE: recent years\n",
            "PERSON: O3\n",
            "GPE: Zaozhuang\n",
            "TIME: hourly\n",
            "DATE: the year 2023\n",
            "ORG: the SHapley Additive Properties Interpretation\n",
            "WORK_OF_ART: Positive Matrix Factorization\n",
            "DATE: June\n",
            "DATE: August\n",
            "DATE: June\n",
            "DATE: August\n",
            "CARDINAL: NO2\n",
            "CARDINAL: six\n",
            "GPE: Zaozhuang\n",
            "MONEY: 5.98 μg/m3\n",
            "CARDINAL: 3.75\n",
            "CARDINAL: 3.06\n",
            "DATE: O3 polluted day\n",
            "PERCENT: 115%\n",
            "PERSON: O3\n",
            "PERCENT: 23%\n",
            "ORG: SHapley Additive Properties Interpretation\n",
            "WORK_OF_ART: Positive Matrix Factorization\n",
            "PERSON: ≤\n",
            "PRODUCT: 1.0 μm\n",
            "GPE: Qingdao\n",
            "LOC: Northern China\n",
            "DATE: two consecutive years\n",
            "DATE: November 1, 2018\n",
            "DATE: January 31, 2019\n",
            "ORG: OP2018–2019\n",
            "DATE: October 28, 2019 to January 20, 2020\n",
            "GPE: OP2019–2020\n",
            "ORG: OP2018–2019\n",
            "PERSON: Cd\n",
            "GPE: PM1\n",
            "GPE: OP2019–2020\n",
            "PERCENT: 61.9%\n",
            "PERCENT: 31.4%\n",
            "PERCENT: 49.2%\n",
            "PERCENT: 25.4%\n",
            "PERCENT: 27.1%\n",
            "PERCENT: 73.3%\n",
            "PERSON: Ni\n",
            "PERCENT: 22.1%\n",
            "ORG: Domestic Emission Control Area\n",
            "DATE: January 1, 2019\n",
            "ORG: the Ministry of Transportation\n",
            "CARDINAL: 2.0\n",
            "EVENT: The Field Emission Scanning Electron Microscope\n",
            "PERSON: Ni\n",
            "GPE: Ni\n",
            "PERCENT: 40.7%\n",
            "CARDINAL: five\n",
            "PERCENT: 47.8%\n",
            "PERCENT: 21.2%\n",
            "PERCENT: 15.1%\n",
            "PERCENT: 11.1%\n",
            "PERCENT: 4.9%\n",
            "CARDINAL: 2.0\n",
            "PERCENT: 5.6% and\n",
            "PERCENT: 3.4%\n",
            "GPE: OP2019–2020\n",
            "GPE: Beijing\n",
            "PERSON: Herein\n",
            "CARDINAL: 0\n",
            "CARDINAL: 0.02\n",
            "CARDINAL: 0.04\n",
            "CARDINAL: 2.7\n",
            "CARDINAL: 1.0\n",
            "CARDINAL: 200\n",
            "GPE: Ag0.94Yb0.02NbO3\n",
            "\n",
            " Researcher: 18-Prashant Mathur\n",
            "Named Entities Found (label: text):\n",
            "GPE: India\n",
            "ORG: the National Cancer Registry Programme\n",
            "ORG: Research of Indian Council of Medical Research\n",
            "DATE: 1982\n",
            "ORG: the 19th International Conference on Spoken Language Translation\n",
            "CARDINAL: eight\n",
            "PERSON: Isometric\n",
            "CARDINAL: 27\n",
            "CARDINAL: at least one\n",
            "ORG: SpeechVerse\n",
            "CARDINAL: zero\n",
            "ORG: SpeechVerse\n",
            "CARDINAL: 9\n",
            "CARDINAL: 11\n",
            "GPE: India\n",
            "ORG: the National NCD Monitoring Survey-(NNMS-2017-\n",
            "DATE: 2018\n",
            "CARDINAL: one\n",
            "DATE: (18–69 years\n",
            "GPE: India\n",
            "PERSON: ≥\n",
            "CARDINAL: 140\n",
            "ORG: DBP\n",
            "PERSON: ≥\n",
            "CARDINAL: 90\n",
            "DATE: the last 14 days\n",
            "ORG: SBP\n",
            "CARDINAL: 140\n",
            "ORG: DBP\n",
            "CARDINAL: 90\n",
            "CARDINAL: 10,593\n",
            "PERCENT: 99.4%\n",
            "DATE: 3017\n",
            "PERCENT: 28.5%\n",
            "PERCENT: 95%\n",
            "CARDINAL: 27.0–30.1\n",
            "CARDINAL: 840\n",
            "PERCENT: 27.9%\n",
            "PERCENT: 95%\n",
            "CARDINAL: 25.5–30.3\n",
            "CARDINAL: 438\n",
            "PERCENT: 14.5%\n",
            "PERCENT: 95%\n",
            "CARDINAL: 12.7–16.5\n",
            "CARDINAL: 379\n",
            "PERCENT: 12.6%\n",
            "PERCENT: 95%\n",
            "DATE: 50–69 years\n",
            "PERCENT: 2.45 95%\n",
            "CARDINAL: 1.63–3.69\n",
            "CARDINAL: 1.63\n",
            "PERCENT: 95%\n",
            "CARDINAL: 1.20–2.22\n",
            "CARDINAL: 4.80\n",
            "PERCENT: 95%\n",
            "DATE: 1.74–13.27\n",
            "CARDINAL: 0.55\n",
            "PERCENT: 95%\n",
            "CARDINAL: One-fifth\n",
            "ORG: the Universal Health Coverage\n",
            "DATE: one quarter\n",
            "LOC: the South-East Asia region\n",
            "PERCENT: 61.7%\n",
            "CARDINAL: 2040.1\n",
            "PERSON: Breast\n",
            "GPE: India\n",
            "PERCENT: 28.2%\n",
            "CARDINAL: an estimated 216,108\n",
            "CARDINAL: 2022.2\n",
            "PERCENT: 39.1%\n",
            "DATE: 1990\n",
            "GPE: India\n",
            "DATE: the past 26 years.3\n",
            "\n",
            "\n",
            "CARDINAL: 5\n",
            "PERCENT: more than 70%\n",
            "NORP: Western\n",
            "GPE: India\n",
            "DATE: 5-year\n",
            "ORG: SURVCAN-3\n",
            "PERSON: Cancer Survival\n",
            "GPE: Countries\n",
            "DATE: 2023\n",
            "DATE: 3-year\n",
            "PERCENT: 84%\n",
            "GPE: India\n",
            "ORG: CONCORD-3\n",
            "CARDINAL: 2010–2014\n",
            "GPE: India\n",
            "DATE: 5-year\n",
            "NORP: Indian\n",
            "DATE: 1981\n",
            "ORG: the National Cancer Registry Programme\n",
            "ORG: the National Center for Disease Informatics and Research (NCDIR\n",
            "ORG: the Indian Council of Medical Research\n",
            "ORG: ICMR-NCDIR-NCRP\n",
            "GPE: Bengaluru\n",
            "DATE: 2017\n",
            "CARDINAL: 25\n",
            "ORG: Population-Based Cancer Registries\n",
            "DATE: 5-year\n",
            "DATE: between 2012 and 2015\n",
            "CARDINAL: 11\n",
            "DATE: 5-year\n",
            "NORP: Asian Indians\n",
            "ORG: NCD\n",
            "LOC: North, South,\n",
            "LOC: East\n",
            "GPE: India\n",
            "DATE: April 2003\n",
            "DATE: March 2005\n",
            "CARDINAL: 44,523\n",
            "DATE: 15–64 years\n",
            "CARDINAL: 15,239\n",
            "CARDINAL: 15,760\n",
            "CARDINAL: 13,524\n",
            "PERCENT: 3.1%\n",
            "PERCENT: 3.2%\n",
            "PERCENT: 7.3%\n",
            "CARDINAL: 2.48\n",
            "PERCENT: 95%\n",
            "ORG: CI\n",
            "DATE: 2.21–2.79\n",
            "PERCENT: 11.3%\n",
            "PERCENT: 0.7%\n",
            "ORG: NCD\n",
            "\n",
            " Researcher: 19-Sanqiang Zhao\n",
            "Named Entities Found (label: text):\n",
            "DATE: daily\n",
            "CARDINAL: two\n",
            "DATE: Recent years\n",
            "ORG: KPG\n",
            "ORG: KPG\n",
            "ORG: KPG\n",
            "ORG: KPG\n",
            "ORG: KPG\n",
            "ORG: WPO\n",
            "PERSON: Alpaca Eval 2\n",
            "ORG: MT\n",
            "ORG: WPO\n",
            "ORG: Direct Preference Optimization\n",
            "ORG: DPO\n",
            "PERCENT: up to 5.6%\n",
            "PERCENT: 76.7%\n",
            "ORG: Gemma-2-9b\n",
            "CARDINAL: One\n",
            "ORG: Modern LLM\n",
            "ORG: the Instructional Segment Embedding\n",
            "ORG: BERT\n",
            "ORG: the Structured Query and Instruction Hierarchy\n",
            "PERCENT: up to 15.75%\n",
            "PERCENT: 18.68%\n",
            "PERCENT: up to 4.1%\n",
            "ORG: AlpacaEval\n",
            "ORG: LLM\n",
            "ORG: NTP\n",
            "ORG: SFT\n",
            "ORG: Mixup\n",
            "ORG: NTP\n",
            "ORG: Mixup\n",
            "ORG: SFT\n",
            "ORG: LLM\n",
            "ORG: SFT\n",
            "CARDINAL: six\n",
            "ORG: aphasia\n",
            "CARDINAL: four\n",
            "PRODUCT: SimSim\n",
            "ORG: Question Answering\n",
            "ORG: QA\n",
            "GPE: QA\n",
            "ORG: StoryQA\n",
            "ORG: QA\n",
            "ORG: QA\n",
            "CARDINAL: four\n",
            "CARDINAL: two\n",
            "ORG: Wikipedia\n",
            "PERSON: Newsela\n",
            "CARDINAL: two\n",
            "CARDINAL: 1\n",
            "CARDINAL: 2\n",
            "CARDINAL: three\n",
            "ORDINAL: first\n",
            "CARDINAL: two\n",
            "CARDINAL: four\n",
            "ORDINAL: third\n",
            "CARDINAL: six\n",
            "ORG: Sentence\n",
            "CARDINAL: two\n",
            "CARDINAL: two\n",
            "CARDINAL: 1\n",
            "CARDINAL: 2\n",
            "ORG: Sobel-LBP\n",
            "ORG: Local Binary Pattern\n",
            "ORG: Sobel\n",
            "ORG: Sobel-LBP\n",
            "PERSON: LBP\n",
            "ORG: Sobel-LBP\n",
            "ORG: LBP\n",
            "ORG: GPT\n",
            "ORG: BERT\n",
            "ORG: XLNet\n",
            "ORG: BERT\n",
            "CARDINAL: more than 60x\n",
            "GPE: BeiHang\n",
            "ORG: BH\n",
            "CARDINAL: three\n",
            "LOC: Nearest Neighbor\n",
            "PERSON: Gaussian Model\n",
            "CARDINAL: One\n",
            "ORG: Transformer\n",
            "ORG: BERT\n",
            "ORG: NLP\n",
            "ORG: BERT\n",
            "ORG: BERT\n",
            "PRODUCT: ICD-9-CM\n",
            "PRODUCT: ICD-9-CM\n",
            "ORG: PubMed\n",
            "ORG: CMC\n",
            "PERSON: Gaussian\n",
            "ORG: KSM\n",
            "ORG: Gabor\n",
            "ORG: Elastic Bunch Graph Matching\n",
            "ORG: EBGM\n",
            "ORG: FERET\n",
            "ORG: Constrained Profile Model\n",
            "PERSON: Flexible Shape Model\n",
            "ORG: FSM\n",
            "ORG: FERET\n",
            "PERSON: Shape Model\n",
            "ORG: ASM\n",
            "ORG: ASM\n",
            "PERSON: Elastic Bunch\n",
            "ORG: EBGM\n",
            "ORG: EBGM\n",
            "CARDINAL: two\n",
            "ORG: EBGM\n",
            "ORG: ASM\n",
            "ORG: EBGM\n",
            "ORG: Multidirectional Binary Pattern\n",
            "ORG: MBP\n",
            "ORG: Local Binary Pattern\n",
            "ORG: LBP\n",
            "ORG: MBP\n",
            "ORG: LBP\n",
            "ORG: MBP\n",
            "ORG: LBP\n",
            "\n",
            " Researcher: 20-Md Mosharaf Hossain\n",
            "Named Entities Found (label: text):\n",
            "CARDINAL: hundreds\n",
            "PERSON: Performance Computing\n",
            "ORG: HPC\n",
            "CARDINAL: eight\n",
            "CARDINAL: six\n",
            "LANGUAGE: English\n",
            "ORG: MT\n",
            "ORG: MT\n",
            "CARDINAL: 17\n",
            "PERCENT: more than 60%\n",
            "CARDINAL: three\n",
            "GPE: Bangladesh\n",
            "DATE: the last few decades\n",
            "GPE: Bangladesh\n",
            "GPE: Bangladesh\n",
            "CARDINAL: three\n",
            "CARDINAL: over 150,000\n",
            "ORG: Support Vector Machines\n",
            "ORG: SVM\n",
            "ORG: linear\n",
            "ORG: Radial Basis Function(RBF\n",
            "DATE: the past two decades\n",
            "GPE: Bangladesh\n",
            "GPE: Bangladesh\n",
            "GPE: Bangladesh\n",
            "ORG: CC\n",
            "ORG: CC\n",
            "PERSON: Neuropilin-1\n",
            "PERSON: Npn1\n",
            "CARDINAL: 3\n",
            "GPE: Plexin\n",
            "PERSON: Npn1\n",
            "ORG: CC\n",
            "PERSON: Npn1\n",
            "CARDINAL: 17.5\n",
            "ORG: KO\n",
            "ORG: WT\n",
            "ORG: CC\n",
            "ORG: CC\n",
            "ORG: CC\n",
            "ORG: CC\n",
            "ORG: BALB/cAJ\n",
            "CARDINAL: 12\n",
            "CARDINAL: three\n",
            "ORG: T1\n",
            "ORG: fed\n",
            "ORG: T2\n",
            "ORG: T3\n",
            "DATE: 90 days\n",
            "DATE: daily\n",
            "GPE: Hb\n",
            "ORG: PCV\n",
            "ORG: MCV\n",
            "CARDINAL: T2\n",
            "ORG: T3\n",
            "CARDINAL: T1\n",
            "PERSON: Aim\n",
            "WORK_OF_ART: Methods and Materials:\n",
            "ORG: the Department of Pediatric\n",
            "Respiratory Medicine (Pulmonology\n",
            "PERSON: Dhaka Shishu (Children) Hospital\n",
            "GPE: Dhaka\n",
            "GPE: Bangladesh\n",
            "DATE: January 2018 to December 2018\n",
            "CARDINAL: 350\n",
            "CARDINAL: 175\n",
            "CARDINAL: 175\n",
            "CARDINAL: 350\n",
            "CARDINAL: 175\n",
            "CARDINAL: 175\n",
            "DATE: 5 to 15 years\n",
            "CARDINAL: 46.2\n",
            "CARDINAL: 32.37\n",
            "DATE: OR= 28.42\n",
            "PERCENT: 95%\n",
            "PERSON: CI\n",
            "DATE: 1.99-50.29\n",
            "CARDINAL: 113.92\n",
            "CARDINAL: 95%CI\n",
            "CARDINAL: 47.25-184.45\n",
            "DATE: OR= 47.84\n",
            "CARDINAL: 149.34\n",
            "PERCENT: 95%\n",
            "CARDINAL: 11.44-201.35\n",
            "DATE: OR= 40.35\n",
            "PERCENT: 95%\n",
            "CARDINAL: 1.82-69.09\n",
            "CARDINAL: 0.047\n",
            "DATE: OR= 2.45\n",
            "PERCENT: 95%\n",
            "CARDINAL: 0.037\n",
            "CARDINAL: 2.70\n",
            "PERCENT: 95%\n",
            "PRODUCT: CI 0.95-\n",
            "7.87\n",
            "CARDINAL: 0.002\n",
            "DATE: OR= 5.06\n",
            "PERCENT: 95%\n",
            "ORG: CI\n",
            "CARDINAL: 1.55-17.54\n",
            "ORG: p<0.05\n",
            "ORG: COVID-19\n",
            "DATE: coming days\n",
            "ORG: COVID-19\n",
            "ORG: Severe Acute Respiratory\n",
            "PERSON: COVID-19\n",
            "PERSON: COVID-19\n",
            "ORG: COVID-19\n",
            "ORG: CEB\n",
            "ORG: MCA\n",
            "ORG: Bangladesh Demographic and Health Survey\n",
            "DATE: 2007\n",
            "CARDINAL: 10,146\n",
            "CARDINAL: 10,996\n",
            "GPE: CEB\n",
            "ORDINAL: first\n",
            "ORDINAL: second\n",
            "ORDINAL: third\n",
            "ORG: CEB\n",
            "GPE: Bangladesh\n",
            "ORG: UHTN\n",
            "GPE: Bangladesh\n",
            "ORG: UHTN\n",
            "DATE: 18 years\n",
            "GPE: Bangladesh\n",
            "DATE: between 2010 and 2024\n",
            "DATE: 1028\n",
            "CARDINAL: nine\n",
            "CARDINAL: 28949\n",
            "GPE: Newcastle\n",
            "ORG: UHTN\n",
            "PERSON: Bangladeshi\n",
            "ORG: UHTN\n",
            "PERCENT: 11%\n",
            "PERCENT: 95%\n",
            "PERCENT: 6%–19%\n",
            "PERCENT: 99.5%\n",
            "PERCENT: 13%\n",
            "PERCENT: 95%\n",
            "PERCENT: 4%–35%\n",
            "PERCENT: 12%\n",
            "PERCENT: 95%\n",
            "PERCENT: 1%–54%\n",
            "PERCENT: 17%\n",
            "PERCENT: 95%\n",
            "PERCENT: 0%–94%\n",
            "ORG: Egger\n",
            "CARDINAL: 0.3113\n",
            "PERSON: Leave-One-Out Analysis\n",
            "ORG: UHTN\n",
            "DATE: 2019\n",
            "CARDINAL: 248\n",
            "DATE: April\n",
            "CARDINAL: 30\n",
            "DATE: May\n",
            "DATE: 30 2020\n",
            "GPE: Bangladesh\n",
            "CARDINAL: 14.2\n",
            "ORG: StataCorp\n",
            "PERSON: Chi-square\n",
            "PERCENT: 5%\n",
            "ORG: COVID-19\n",
            "PERCENT: 86.29%\n",
            "PERCENT: 71.37%\n",
            "PERCENT: 47.98%\n",
            "PERSON: COVID-19\n",
            "GPE: Bangladesh\n",
            "ORG: Convolutional Neural Networks\n",
            "ORG: CNN\n",
            "ORG: CNN\n",
            "ORG: CNN\n",
            "ORG: Brute\n",
            "ORG: CNN\n",
            "ORG: Brute\n",
            "ORG: Brute\n",
            "CARDINAL: Twenty\n",
            "GPE: Dhaka\n",
            "ORG: DCC\n",
            "GPE: Bangladesh\n",
            "ORG: DCC\n",
            "CARDINAL: two\n",
            "ORDINAL: first\n",
            "CARDINAL: fifty\n",
            "CARDINAL: ten\n",
            "PERSON: i.e chromium\n",
            "ORDINAL: second\n",
            "CARDINAL: fifty\n",
            "CARDINAL: ten\n",
            "ORG: DCC\n",
            "ORDINAL: first\n",
            "CARDINAL: 100\n",
            "ORG: Cr, Cd, Pb\n",
            "ORDINAL: first\n",
            "ORG: P>0.05\n",
            "ORDINAL: second\n"
          ]
        }
      ]
    }
  ]
}